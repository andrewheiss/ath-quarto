[
  {"id":"BenderHanna:2025","abstract":"\"Is artificial intelligence going to take over the world? Have big tech scientists created an artificial lifeform that can think on its own? Is it going to put authors, artists, and others out of business? Are we about to enter an age where computers are better than humans at everything? The answer to these questions, linguist Emily M. Bender and sociologist Alex Hanna make clear, is \"no,\" \"they wish,\" \"LOL,\" and \"definitely not.\" This kind of thinking is a symptom of a phenomenon known as \"AI hype.\" Hype looks and smells fishy: It twists words and helps the rich get richer by justifying data theft, motivating surveillance capitalism, and devaluing human creativity in order to replace meaningful work with jobs that treat people like machines. In The AI Con, Bender and Hanna offer a sharp, witty, and wide-ranging take-down of AI hype across its many forms. Bender and Hanna show you how to spot AI hype, how to deconstruct it, and how to expose the power grabs it aims to hide. Armed with these tools, you will be prepared to push back against AI hype at work, as a consumer in the marketplace, as a skeptical newsreader, and as a citizen holding policymakers to account. Together, Bender and Hanna expose AI hype for what it is: a mask for Big Tech's drive for profit, with little concern for who it affects.\"","author":[{"family":"Bender","given":"Emily M."},{"family":"Hanna","given":"Alex"}],"citation-key":"BenderHanna:2025","event-place":"New York","ISBN":"978-0-06-341856-1","issued":{"date-parts":[["2025"]]},"language":"eng","number-of-pages":"274","publisher":"HarperCollins","publisher-place":"New York","source":"K10plus ISBN","title":"The AI Con: How to fight big tech's hype and create the future we want","title-short":"The AI Con","type":"book"},
  {"id":"Chiang:2024","abstract":"To create a novel or a painting, an artist makes choices that are fundamentally alien to artificial intelligence.","accessed":{"date-parts":[["2025",7,20]]},"author":[{"family":"Chiang","given":"Ted"}],"citation-key":"Chiang:2024","container-title":"The New Yorker","ISSN":"0028-792X","issued":{"date-parts":[["2024",8,31]]},"language":"en-US","section":"the weekend essay","source":"www.newyorker.com","title":"Why A.I. isn’t going to make art","type":"article-magazine","URL":"https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art"},
  {"id":"Frankfurt:2005","author":[{"family":"Frankfurt","given":"Harry G."}],"citation-key":"Frankfurt:2005","event-place":"Princeton","issued":{"date-parts":[["2005"]]},"publisher":"Princeton University Press","publisher-place":"Princeton","title":"On bullshit","type":"book"},
  {"id":"Hao:2025","author":[{"family":"Hao","given":"Karen"}],"citation-key":"Hao:2025","event-place":"New York","ISBN":"978-0-593-65750-8 978-0-593-65751-5","issued":{"date-parts":[["2025"]]},"language":"eng","number-of-pages":"1","publisher":"Penguin Press","publisher-place":"New York","source":"K10plus ISBN","title":"Empire of AI: Dreams and nightmares in Sam Altman's OpenAI","title-short":"Empire of AI","type":"book"},
  {"id":"HicksHumphriesSlater:2024","abstract":"Abstract\n            \n              Recently, there has been considerable interest in large language models: machine learning systems which produce human-like text and dialogue. Applications of these systems have been plagued by persistent inaccuracies in their output; these are often called “AI hallucinations”. We argue that these falsehoods, and the overall activity of large language models, is better understood as\n              bullshit\n              in the sense explored by Frankfurt (On Bullshit, Princeton, 2005): the models are in an important way indifferent to the truth of their outputs. We distinguish two ways in which the models can be said to be bullshitters, and argue that they clearly meet at least one of these definitions. We further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.","accessed":{"date-parts":[["2024",6,19]]},"author":[{"family":"Hicks","given":"Michael Townsen"},{"family":"Humphries","given":"James"},{"family":"Slater","given":"Joe"}],"citation-key":"HicksHumphriesSlater:2024","container-title":"Ethics and Information Technology","container-title-short":"Ethics Inf. Technol.","DOI":"10.1007/s10676-024-09775-5","ISSN":"1388-1957, 1572-8439","issue":"2","issued":{"date-parts":[["2024",6]]},"language":"en-US","page":"38","source":"DOI.org (Crossref)","title":"ChatGPT is bullshit","type":"article-journal","URL":"https://link.springer.com/10.1007/s10676-024-09775-5","volume":"26"},
  {"id":"Rosenzweig:2023","abstract":"AI is on the verge of becoming a standard feature of word processing. The danger is that it will discourage us from thinking for ourselves.","accessed":{"date-parts":[["2024",8,19]]},"author":[{"family":"Rosenzweig","given":"Jane"}],"citation-key":"Rosenzweig:2023","container-title":"Los Angeles Times","issued":{"date-parts":[["2023",6,20]]},"language":"en-US","title":"AI-assisted writing is close to becoming as standard as spell check. Here's the catch","type":"webpage","URL":"https://www.latimes.com/opinion/story/2023-06-20/google-microsoft-chatgpt-ai-writing-assistants-artificial-intelligence"}
]

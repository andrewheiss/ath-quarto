{
  "hash": "d99ef15a71e9e737fcbc57fcd7c7481f",
  "result": {
    "markdown": "---\ntitle: \"A guide to Bayesian proportion tests with R and {brms}\"\ndate: 2023-05-15\ndescription: \"Use R, Stan, and {brms} to calculate differences between categorical proportions in a principled Bayesian way\"\nimage: index_files/figure-html/q2-plot-final-1.png\ntwitter-card: \n    image: \"index_files/figure-html/q2-plot-final-1.png\"\nopen-graph: \n    image: \"index_files/figure-html/q2-plot-final-1.png\"\ncategories:\n  - r\n  - tidyverse\n  - ggplot\n  - bayes\n  - brms\n  - stan\n  - surveys\n  - categorical data\nformat:\n  html:\n    reference-location: margin\n    code-fold: show\ndoi: 10.59350/kw2gj-kw740\ncitation: true\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n<style type=\"text/css\">\n.magic-block {\n  font-style: normal;\n  user-select: none;\n  padding: 0 0.1em 0 0.15em;\n  line-height: 1;\n  font-size: 120%;\n}\n</style>\n:::\n\n\nI've been working on converting a couple of my dissertation chapters into standalone articles, so I've been revisiting and improving my older R code. As part of my dissertation work, I ran a global survey of international NGOs to see how they adjust their programs and strategies when working under authoritarian legal restrictions in dictatorship. In the survey, I asked a bunch of questions with categorical responses (like \"How would you characterize your organization's relationship with your host-country government?\", with the possible responses \"Positive,\" \"Negative\", and \"Neither\"). \n\nAnalyzing this kind of categorical data can be tricky. What I ended up doing (and what people typically do) is looking at the differences in proportions of responses (i.e. is there a substantial difference in the proportion reporting \"Positive\" or \"Negative\" in different subgroups?). But doing this requires a little bit of extra work because of how proportions work. We can't just treat proportions like continuous values. Denominators matter and help determine the level of uncertainty in the proportions. We need to account for these disparate sample sizes underlying the proportions.\n\nAdditionally, it's tempting to treat [Likert scale responses](https://en.wikipedia.org/wiki/Likert_scale)^[Pronounced \"lick-ert\"!] (i.e. things like \"strongly agree\", \"agree\", \"neutral\", etc.) as numbers (e.g. make \"strongly agree\" a 2, \"agree\" a 1, \"neutral\" a 0, and so on), and then find things like averages (e.g. \"the average response is a 1.34\"), but those summary statistics aren't actually that accurate. What would a 1.34 mean? A little higher than agree? What does that even mean?\n\nWe need to treat these kinds of survey questions as the categories that they are, which requires a different set of analytical tools than just findings averages and running linear regressions. We instead need to use things like frequencies, proportions, [contingency tables and crosstabs](https://en.wikipedia.org/wiki/Contingency_table), and fancier regression like ordered logistic models.\n\nI'm a fan of Bayesian statistical inference—I find it way more intuitive and straightforward than frequentist null hypothesis testing. I first \"converted\" to Bayesianism back when I first analyzed my dissertation data in 2017 and used the newly-invented [{rstanarm} package](https://mc-stan.org/rstanarm/) to calculate the difference in proportions of my various survey responses in Bayesian ways, based on [a blog post and package for Bayesian proportion tests by Rasmus Bååth](https://www.sumsar.net/blog/2014/06/bayesian-first-aid-prop-test/). He used [JAGS](https://mcmc-jags.sourceforge.io/), though, and I prefer to use [Stan](https://mc-stan.org/), hence my use of {rstanarm} back then.\n\nSince 2017, though, I've learned a lot more about Bayesianism. I've [worked](https://bayesf22.classes.andrewheiss.com/) [through](https://bayesf22-notebook.classes.andrewheiss.com/) both [Richard McElreath's *Statistical Rethinking*](https://xcelab.net/rm/statistical-rethinking/) and [the gloriously accessible *Bayes Rules!*](https://www.bayesrulesbook.com/), and I no longer use {rstanarm}. I instead use [{brms}](https://paul-buerkner.github.io/brms/) for everything (or raw Stan if I'm feeling extra fancy).\n\nSo, as a reference for myself while rewriting these chapters, and as a way to consolidate everything I've learned about Bayesian-flavored proportion tests, here's a guide to thinking about differences in proportions in a principled Bayesian way. I explore two different questions (explained in detail below). For the first one I'll be super pedagogical and long-winded, showing how to find differences in proportions with classical frequentist statistical tests, with different variations of Stan code, and with different variations of {brms} code. For the second one I'll be less pedagogical and just show the code and results.\n\n\n# Who this post is for\n\nHere's what I assume you know:\n\n- You're familiar with [R](https://www.r-project.org/) and the [tidyverse](https://www.tidyverse.org/) (particularly [{dplyr}](https://dplyr.tidyverse.org/) and [{ggplot2}](https://ggplot2.tidyverse.org/)).\n- You're familiar with [{brms}](https://paul-buerkner.github.io/brms/) for running Bayesian regression models and [{tidybayes}](https://mjskay.github.io/tidybayes/) and [{ggdist}](https://mjskay.github.io/ggdist/) for manipulating and plotting posterior draws\n\n\n# Wrangling and exploring the data\n\nBefore getting started, let's load all the packages we need and create some helpful functions and variables:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)    # ggplot, dplyr, and friends\nlibrary(gt)           # Fancy tables\nlibrary(glue)         # Easier string interpolation\nlibrary(scales)       # Nicer labeling functions\nlibrary(ggmosaic)     # Mosaic plots with ggplot\nlibrary(ggpattern)    # Pattern fills in ggplot\nlibrary(patchwork)    # Combine plots nicely\nlibrary(parameters)   # Extract model parameters as data frames\nlibrary(cmdstanr)     # Run Stan code from R\nlibrary(brms)         # Nice frontend for Stan\nlibrary(tidybayes)    # Manipulate MCMC chains in a tidy way\nlibrary(likert)       # Contains the pisaitems data\n\n# Use the cmdstanr backend for brms because it's faster and more modern than the\n# default rstan backend. You need to install the cmdstanr package first\n# (https://mc-stan.org/cmdstanr/) and then run cmdstanr::install_cmdstan() to\n# install cmdstan on your computer.\noptions(mc.cores = 4,\n        brms.backend = \"cmdstanr\")\n\n# Set some global Stan options\nCHAINS <- 4\nITER <- 2000\nWARMUP <- 1000\nBAYES_SEED <- 1234\n\n# Custom ggplot theme to make pretty plots\n# Get the font at https://fonts.google.com/specimen/Jost\ntheme_nice <- function() {\n  theme_minimal(base_family = \"Jost\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(family = \"Jost\", face = \"bold\"),\n          axis.title = element_text(family = \"Jost Medium\"),\n          axis.title.x = element_text(hjust = 0),\n          axis.title.y = element_text(hjust = 1),\n          strip.text = element_text(family = \"Jost\", face = \"bold\",\n                                    size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = NA, color = NA))\n}\n\n# Function for formatting axes as percentage points\nlabel_pp <- label_number(accuracy = 1, scale = 100, \n                         suffix = \" pp.\", style_negative = \"minus\")\n```\n:::\n\n\n\n\n\n\nThroughout this guide, we'll use data from the 2009 [Programme of International Student Assessment (PISA) survey](https://en.wikipedia.org/wiki/Programme_for_International_Student_Assessment), which is available in the [{likert} package](https://github.com/jbryer/likert). PISA is administered every three years to 15-year-old students in dozens of countries, and it tracks academic performance, outcomes, and student attitudes cross-nationally. \n\nOne of the questions on the [PISA student questionnaire](https://www.oecd.org/pisa/pisaproducts/PISA09_Student_questionnaire.pdf) (Q25) asks respondents how often they read different types of materials:\n\n![2009 PISA Q25](img/pisa.png)\n\nThe excerpt of PISA data included in the {likert} package only includes responses from Canada, Mexico, and the United States, and for this question it seems to omit data from Canada, so we'll compare the reading frequencies of American and Mexican students. Specifically we'll look at how these students read comic books and newspapers. My wife is currently finishing her masters thesis on religious representation in graphic novels, and I'm a fan of comics in general, so it'll be interesting to see how students in the two countries read these books. We'll look at newspapers because it's an interesting category with some helpful variation (reading trends for magazines, fiction, and nonfiction look basically the same in both countries so we'll ignore them here.)\n\nFirst we'll load and clean the data. For the sake of illustration in this post, I collapse the five possible responses into just three:\n\n- Rarely = Never or almost never\n- Sometimes = A few times a year & About once a month\n- Often = Several times a month & Several times a week\n\nIn real life it's typically a bad idea to collapse categories like this, and I'm not an education researcher so this collapsing is probably bad and wrong, but whatever—just go with it :)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the data\ndata(\"pisaitems\", package = \"likert\")\n\n# Make a clean wide version of the data\nreading_wide <- pisaitems %>% \n  # Add ID column\n  mutate(id = 1:n()) %>%\n  # Only keep a few columns\n  select(id, country = CNT, `Comic books` = ST25Q02, Newspapers = ST25Q05) %>% \n  # Collapse these categories\n  mutate(across(c(`Comic books`, Newspapers), \n                ~fct_collapse(\n                  .,\n                  \"Rarely\" = c(\"Never or almost never\"),\n                  \"Sometimes\" = c(\"A few times a year\", \"About once a month\"),\n                  \"Often\" = c(\"Several times a month\", \"Several times a week\")))) %>% \n  # Make sure the new categories are ordered correctly\n  mutate(across(c(`Comic books`, Newspapers), \n                ~fct_relevel(., c(\"Rarely\", \"Sometimes\", \"Often\")))) %>% \n  # Only keep the US and Mexico and get rid of the empty Canada level\n  filter(country %in% c(\"United States\", \"Mexico\")) %>% \n  mutate(country = fct_drop(country))\nhead(reading_wide)\n##      id country Comic books Newspapers\n## 1 23208  Mexico   Sometimes      Often\n## 2 23209  Mexico      Rarely      Often\n## 3 23210  Mexico       Often      Often\n## 4 23211  Mexico   Sometimes  Sometimes\n## 5 23212  Mexico      Rarely      Often\n## 6 23213  Mexico   Sometimes  Sometimes\n\n# Make a tidy (long) version\nreading <- reading_wide %>% \n  pivot_longer(-c(id, country),\n               names_to = \"book_type\",\n               values_to = \"frequency\") %>% \n  drop_na(frequency)\nhead(reading)\n## # A tibble: 6 × 4\n##      id country book_type   frequency\n##   <int> <fct>   <chr>       <fct>    \n## 1 23208 Mexico  Comic books Sometimes\n## 2 23208 Mexico  Newspapers  Often    \n## 3 23209 Mexico  Comic books Rarely   \n## 4 23209 Mexico  Newspapers  Often    \n## 5 23210 Mexico  Comic books Often    \n## 6 23210 Mexico  Newspapers  Often\n```\n:::\n\n\nSince we created a tidy (long) version of the data, we can use {dplyr} to create some overall group summaries of reading frequency by type of material across countries. Having data in this format, with a column for the specific total (i.e. Mexico + Comic books + Rarely, and so on, or `n` here) and the overall country total (or `total` here), allows us to calculate group proportions (`n / total`):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreading_counts <- reading %>% \n  group_by(country, book_type, frequency) %>% \n  summarize(n = n()) %>% \n  group_by(country, book_type) %>% \n  mutate(total = sum(n),\n         prop = n / sum(n)) %>% \n  ungroup()\nreading_counts\n## # A tibble: 12 × 6\n##    country       book_type   frequency     n total  prop\n##    <fct>         <chr>       <fct>     <int> <int> <dbl>\n##  1 Mexico        Comic books Rarely     9897 37641 0.263\n##  2 Mexico        Comic books Sometimes 17139 37641 0.455\n##  3 Mexico        Comic books Often     10605 37641 0.282\n##  4 Mexico        Newspapers  Rarely     6812 37794 0.180\n##  5 Mexico        Newspapers  Sometimes 12369 37794 0.327\n##  6 Mexico        Newspapers  Often     18613 37794 0.492\n##  7 United States Comic books Rarely     3237  5142 0.630\n##  8 United States Comic books Sometimes  1381  5142 0.269\n##  9 United States Comic books Often       524  5142 0.102\n## 10 United States Newspapers  Rarely     1307  5172 0.253\n## 11 United States Newspapers  Sometimes  1925  5172 0.372\n## 12 United States Newspapers  Often      1940  5172 0.375\n```\n:::\n\n\nAnd we can do a little pivoting and formatting and make this nice little contingency table / crosstab summarizing the data across the two countries:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfancy_table <- reading_counts %>% \n  mutate(nice = glue(\"{prop}<br><span style='font-size:70%'>({n})</span>\",\n                     prop = label_percent()(prop),\n                     n = label_comma()(n))) %>% \n  select(-n, -prop, -total) %>% \n  pivot_wider(names_from = \"frequency\",\n              values_from = \"nice\") %>% \n  group_by(country) %>%\n  gt() %>%\n  cols_label(\n    book_type = \"\",\n  ) %>%\n  fmt_markdown(\n    columns = everything()\n  ) %>% \n  opt_horizontal_padding(3) %>% \n  opt_table_font(font = \"Fira Sans\") %>% \n  tab_options(column_labels.font.weight = \"bold\",\n              row_group.font.weight = \"bold\")\nfancy_table\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"pzveloiefp\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pzveloiefp table {\n  font-family: 'Fira Sans', system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pzveloiefp thead, #pzveloiefp tbody, #pzveloiefp tfoot, #pzveloiefp tr, #pzveloiefp td, #pzveloiefp th {\n  border-style: none;\n}\n\n#pzveloiefp p {\n  margin: 0;\n  padding: 0;\n}\n\n#pzveloiefp .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pzveloiefp .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pzveloiefp .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pzveloiefp .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 15px;\n  padding-right: 15px;\n  overflow-x: hidden;\n}\n\n#pzveloiefp .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pzveloiefp .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pzveloiefp .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pzveloiefp .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pzveloiefp .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pzveloiefp .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pzveloiefp .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pzveloiefp .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pzveloiefp .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pzveloiefp .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pzveloiefp .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#pzveloiefp .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n  vertical-align: top;\n}\n\n#pzveloiefp .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pzveloiefp .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pzveloiefp .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#pzveloiefp .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pzveloiefp .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#pzveloiefp .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pzveloiefp .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#pzveloiefp .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pzveloiefp .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#pzveloiefp .gt_left {\n  text-align: left;\n}\n\n#pzveloiefp .gt_center {\n  text-align: center;\n}\n\n#pzveloiefp .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pzveloiefp .gt_font_normal {\n  font-weight: normal;\n}\n\n#pzveloiefp .gt_font_bold {\n  font-weight: bold;\n}\n\n#pzveloiefp .gt_font_italic {\n  font-style: italic;\n}\n\n#pzveloiefp .gt_super {\n  font-size: 65%;\n}\n\n#pzveloiefp .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pzveloiefp .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pzveloiefp .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pzveloiefp .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pzveloiefp .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pzveloiefp .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pzveloiefp .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Rarely\">Rarely</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Sometimes\">Sometimes</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Often\">Often</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"Mexico\">Mexico</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.29%<br><span style='font-size:70%'>(9,897)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>45.53%<br><span style='font-size:70%'>(17,139)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>28.17%<br><span style='font-size:70%'>(10,605)</span></p>\n</div></td></tr>\n    <tr><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>18.02%<br><span style='font-size:70%'>(6,812)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>32.73%<br><span style='font-size:70%'>(12,369)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>49.25%<br><span style='font-size:70%'>(18,613)</span></p>\n</div></td></tr>\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"United States\">United States</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>62.95%<br><span style='font-size:70%'>(3,237)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.86%<br><span style='font-size:70%'>(1,381)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>10.19%<br><span style='font-size:70%'>(524)</span></p>\n</div></td></tr>\n    <tr><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>25.27%<br><span style='font-size:70%'>(1,307)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>37.22%<br><span style='font-size:70%'>(1,925)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>37.51%<br><span style='font-size:70%'>(1,940)</span></p>\n</div></td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\nThis table has a lot of numbers and it's hard to immediately see what's going on, so we'll visualize it really quick to get a sense for some of the initial trends. Visualizing this is a little tricky though. It's easy enough to make a bar chart of the percentages, but doing that is a little misleading. Notice the huge differences in the numbers of respondents here—there are thousands of Mexican students and only hundreds of American students. [We should probably visualize the data in a way that accounts for these different denominators](https://clauswilke.com/dataviz/nested-proportions.html), and percentages by themselves don't do that.\n\nWe can use a [mosaic plot](https://en.wikipedia.org/wiki/Mosaic_plot) (also known as a [Marimekko chart](https://datavizcatalogue.com/methods/marimekko_chart.html)) to visualize both the distribution of proportions of responses (Rarely, Sometimes, Often) and the proportions of respondents from each country (Mexico and the United States). We can use the [{ggmosaic} package](https://haleyjeppson.github.io/ggmosaic/) to create ggplot-flavored mosaic plots:\n\n::: {.callout-tip}\n## Base R works too!\n\nMosaic plots are actually also built into base R! \n\nTry running `plot(table(mtcars$cyl, mtcars$am))`.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(reading) +\n  geom_mosaic(aes(x = product(frequency, country),  # Look at combination of frequency by country\n                  fill = frequency, alpha = country),\n              divider = mosaic(\"v\"),  # Make the plot divide vertically\n              offset = 0, color = \"white\", linewidth = 1) +  # Add thin white border around boxes\n  scale_x_productlist(expand = c(0, 0.02)) +  # Make the x-axis take up almost the full panel width, with 2% spacing on each side\n  scale_y_productlist(expand = c(0, 0)) +  # Make the y-axis take up the full panel width\n  scale_fill_manual(values = c(\"#E51B24\", \"#FFDE00\", \"#009DDC\"), guide = \"none\") +\n  scale_alpha_manual(values = c(0.6, 1), guide = \"none\") +\n  facet_wrap(vars(book_type)) +\n  theme_nice() +\n  theme(panel.grid.major.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        # Using labs(x = NULL) with scale_x_productlist() apparently doesn't\n        # work, so we can turn off the axis title with theme() instead\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Mosaic plot of the proportions of comic book and newspaper reading frequency in the United States and Mexico](index_files/figure-html/plot-mosaic-1.png){fig-align='center' fig-alt='Mosaic plot of the proportions of comic book and newspaper reading frequency in the United States and Mexico' width=90%}\n:::\n:::\n\n\nThere are a few quick things to point out here in this plot. The Mexico rectangles are super tall, since there are so many more respondents from Mexico than from the United States. It looks like the majority of American students only rarely read comic books, while their Mexican counterparts do it either sometimes or often. Mexican students also read newspapers a lot more than Americans do, with \"Often\" the clear most common category. For Americans, the \"Sometimes\" and \"Often\" newspaper responses look about the same.\n\n\n# The questions\n\nThroughout this post, I'll illustrate the logic of Bayesian proportion tests by answering two questions that I had while looking at the contingency table and mosaic plot above:\n\n1. Do students in Mexico read comic books more often than students in the United States? (the <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>two yellow cells in the \"Often\" column</span>)\n2. Do students in the United States vary in their frequency of reading newspapers? (the <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>blue row for newspapers in the United States</span>)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfancy_table %>% \n  tab_style(\n    style = list(\n      cell_fill(color = colorspace::lighten(\"#CD8A39\", 0.7)),\n      cell_text(color = \"#CD8A39\", weight = \"bold\")\n    ),\n    locations = list(\n      cells_body(columns = \"Often\", rows = c(1, 3))\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_fill(color = colorspace::lighten(\"#009DDC\", 0.8)),\n      cell_text(color = \"#009DDC\", weight = \"bold\")\n    ),\n    locations = list(\n      cells_body(columns = 3:5, rows = 4)\n    )\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"dbgvzfontn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#dbgvzfontn table {\n  font-family: 'Fira Sans', system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#dbgvzfontn thead, #dbgvzfontn tbody, #dbgvzfontn tfoot, #dbgvzfontn tr, #dbgvzfontn td, #dbgvzfontn th {\n  border-style: none;\n}\n\n#dbgvzfontn p {\n  margin: 0;\n  padding: 0;\n}\n\n#dbgvzfontn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#dbgvzfontn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#dbgvzfontn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#dbgvzfontn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 15px;\n  padding-right: 15px;\n  overflow-x: hidden;\n}\n\n#dbgvzfontn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#dbgvzfontn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#dbgvzfontn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#dbgvzfontn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#dbgvzfontn .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#dbgvzfontn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#dbgvzfontn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#dbgvzfontn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#dbgvzfontn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#dbgvzfontn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#dbgvzfontn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#dbgvzfontn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n  vertical-align: top;\n}\n\n#dbgvzfontn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#dbgvzfontn .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#dbgvzfontn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#dbgvzfontn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#dbgvzfontn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#dbgvzfontn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#dbgvzfontn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#dbgvzfontn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#dbgvzfontn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#dbgvzfontn .gt_left {\n  text-align: left;\n}\n\n#dbgvzfontn .gt_center {\n  text-align: center;\n}\n\n#dbgvzfontn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#dbgvzfontn .gt_font_normal {\n  font-weight: normal;\n}\n\n#dbgvzfontn .gt_font_bold {\n  font-weight: bold;\n}\n\n#dbgvzfontn .gt_font_italic {\n  font-style: italic;\n}\n\n#dbgvzfontn .gt_super {\n  font-size: 65%;\n}\n\n#dbgvzfontn .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#dbgvzfontn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#dbgvzfontn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#dbgvzfontn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#dbgvzfontn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#dbgvzfontn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#dbgvzfontn .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Rarely\">Rarely</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Sometimes\">Sometimes</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Often\">Often</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"Mexico\">Mexico</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.29%<br><span style='font-size:70%'>(9,897)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>45.53%<br><span style='font-size:70%'>(17,139)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\" style=\"background-color: #FFD8BB; color: #CD8A39; font-weight: bold;\"><div class='gt_from_md'><p>28.17%<br><span style='font-size:70%'>(10,605)</span></p>\n</div></td></tr>\n    <tr><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>18.02%<br><span style='font-size:70%'>(6,812)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>32.73%<br><span style='font-size:70%'>(12,369)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>49.25%<br><span style='font-size:70%'>(18,613)</span></p>\n</div></td></tr>\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"United States\">United States</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>62.95%<br><span style='font-size:70%'>(3,237)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.86%<br><span style='font-size:70%'>(1,381)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\" style=\"background-color: #FFD8BB; color: #CD8A39; font-weight: bold;\"><div class='gt_from_md'><p>10.19%<br><span style='font-size:70%'>(524)</span></p>\n</div></td></tr>\n    <tr><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\" style=\"background-color: #D7EBFF; color: #009DDC; font-weight: bold;\"><div class='gt_from_md'><p>25.27%<br><span style='font-size:70%'>(1,307)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\" style=\"background-color: #D7EBFF; color: #009DDC; font-weight: bold;\"><div class='gt_from_md'><p>37.22%<br><span style='font-size:70%'>(1,925)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\" style=\"background-color: #D7EBFF; color: #009DDC; font-weight: bold;\"><div class='gt_from_md'><p>37.51%<br><span style='font-size:70%'>(1,940)</span></p>\n</div></td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n# Question 1: Comic book readership in the US vs. Mexico\n\n## Estimand\n\nFor our first question, we want to know if there's a substantial difference in the proportion of students who read comic books often in the United States and Mexico, or whether the difference between the <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>two yellow cells</span> is greater than zero:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfancy_table %>% \n  tab_style(\n    style = list(\n      cell_fill(color = colorspace::lighten(\"#CD8A39\", 0.7)),\n      cell_text(color = \"#CD8A39\", weight = \"bold\")\n    ),\n    locations = list(\n      cells_body(columns = \"Often\", rows = c(1, 3))\n    )\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"xdduhtxcdz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#xdduhtxcdz table {\n  font-family: 'Fira Sans', system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#xdduhtxcdz thead, #xdduhtxcdz tbody, #xdduhtxcdz tfoot, #xdduhtxcdz tr, #xdduhtxcdz td, #xdduhtxcdz th {\n  border-style: none;\n}\n\n#xdduhtxcdz p {\n  margin: 0;\n  padding: 0;\n}\n\n#xdduhtxcdz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#xdduhtxcdz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#xdduhtxcdz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#xdduhtxcdz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 15px;\n  padding-right: 15px;\n  overflow-x: hidden;\n}\n\n#xdduhtxcdz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#xdduhtxcdz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#xdduhtxcdz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#xdduhtxcdz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#xdduhtxcdz .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#xdduhtxcdz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#xdduhtxcdz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#xdduhtxcdz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#xdduhtxcdz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#xdduhtxcdz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#xdduhtxcdz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#xdduhtxcdz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n  vertical-align: top;\n}\n\n#xdduhtxcdz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#xdduhtxcdz .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#xdduhtxcdz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#xdduhtxcdz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#xdduhtxcdz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#xdduhtxcdz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#xdduhtxcdz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#xdduhtxcdz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xdduhtxcdz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#xdduhtxcdz .gt_left {\n  text-align: left;\n}\n\n#xdduhtxcdz .gt_center {\n  text-align: center;\n}\n\n#xdduhtxcdz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#xdduhtxcdz .gt_font_normal {\n  font-weight: normal;\n}\n\n#xdduhtxcdz .gt_font_bold {\n  font-weight: bold;\n}\n\n#xdduhtxcdz .gt_font_italic {\n  font-style: italic;\n}\n\n#xdduhtxcdz .gt_super {\n  font-size: 65%;\n}\n\n#xdduhtxcdz .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#xdduhtxcdz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#xdduhtxcdz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#xdduhtxcdz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#xdduhtxcdz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#xdduhtxcdz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#xdduhtxcdz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Rarely\">Rarely</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Sometimes\">Sometimes</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Often\">Often</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"Mexico\">Mexico</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.29%<br><span style='font-size:70%'>(9,897)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>45.53%<br><span style='font-size:70%'>(17,139)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\" style=\"background-color: #FFD8BB; color: #CD8A39; font-weight: bold;\"><div class='gt_from_md'><p>28.17%<br><span style='font-size:70%'>(10,605)</span></p>\n</div></td></tr>\n    <tr><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>18.02%<br><span style='font-size:70%'>(6,812)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>32.73%<br><span style='font-size:70%'>(12,369)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>49.25%<br><span style='font-size:70%'>(18,613)</span></p>\n</div></td></tr>\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"United States\">United States</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>62.95%<br><span style='font-size:70%'>(3,237)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.86%<br><span style='font-size:70%'>(1,381)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\" style=\"background-color: #FFD8BB; color: #CD8A39; font-weight: bold;\"><div class='gt_from_md'><p>10.19%<br><span style='font-size:70%'>(524)</span></p>\n</div></td></tr>\n    <tr><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>25.27%<br><span style='font-size:70%'>(1,307)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>37.22%<br><span style='font-size:70%'>(1,925)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>37.51%<br><span style='font-size:70%'>(1,940)</span></p>\n</div></td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\nTo be more formal about this, we'll call this estimand $\\theta$, which is the difference between the two proportions $\\pi$:\n\n$$\n\\theta = \\pi_\\text{Mexico, comic books, often} - \\pi_\\text{United States, comic books, often}\n$$\n\nWhen visualizing this, we'll use colors to help communicate the idea of between-group differences. We'll get fancier with the colors in question 2, where we'll look at three sets of pairwise differences, but here we're just looking at a single pairwise difference (the difference between the US and Mexico), so we'll use a bit of subtle and not-quite-correct color theory. In kindergarten we all learned the [RYB color model](https://en.wikipedia.org/wiki/RYB_color_model), where primary pigments can be mixed to create secondary pigments. For instance\n\n><span style=\"color: #0074D9\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>blue</span> + <span style=\"color: #FFDC00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow</span> = <span style=\"color: #2ECC40\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>green</span>. \n\nIf we do some (wrong color-theory-wise) algebra, we can rearrange the formula so that \n\n> <span style=\"color: #0074D9\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>blue</span> − <span style=\"color: #2ECC40\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>green</span> = <span style=\"color: #FFDC00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow</span>\n\nIf we make the United States <span style=\"color: #0074D9\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>blue</span> and Mexico <span style=\"color: #2ECC40\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>green</span>, the ostensible color for their difference is <span style=\"color: #FFDC00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow</span>. This is TOTALLY WRONG and [a lot more complicated](https://xkcd.com/1882/) according to actual color theory, but it's a cute and subtle visual cue, so we'll use it.\n\nThese primary colors are a little too bright for my taste though, so let's artsty them up a bit. We're looking at data about the US and Mexico, so we'll use the Saguaro palette from [the {NatParksPalettes} package](https://github.com/kevinsblake/NatParksPalettes), since [Saguaro National Park](https://en.wikipedia.org/wiki/Saguaro_National_Park) is near the US-Mexico border and it has a nice blue, yellow, and green.\n\nWe'll use <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow for the difference (θ)</span> between the <span style=\"color: #127088\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>United States</span> and <span style=\"color: #57643C\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>Mexico</span>.\n\n::: {.column-margin}\n![](img/saguaro.jpg)\n\n[\"Saguaro Fruit Ripens in June\"](https://www.nps.gov/media/photo/gallery-item.htm?pg=1937068&id=D0458FC7-155D-451F-678551BE57482110&gid=D0377EAB-155D-451F-67573A9D0FD80A08) by the [US National Park Service](https://www.nps.gov/)\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# US/Mexico question colors\nclrs_saguaro <- NatParksPalettes::natparks.pals(\"Saguaro\")\nclr_usa <- clrs_saguaro[1]\nclr_mex <- clrs_saguaro[6]\nclr_diff <- clrs_saguaro[4]\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/show-saguaro-pal-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Classically\n\nIn classical frequentist statistics, there are lots of ways to test for the significance of a difference in proportions of counts, rates, proportions, and other categorical-related things, like chi-squared tests, [Fisher's exact test](https://www.tjmahr.com/bayesian-fisher-exact-test/), or proportion tests. Each of these tests have special corresponding \"flavors\" that apply to specific conditions within the data being tested or the estimand being calculated (corrections for sample sizes, etc.). In standard stats classes, you memorize [big flowcharts of possible statistical operations](https://www.google.com/search?q=statistical+test+flow+chart) and select the correct one for the situation.\n\nSince we want to test the difference between two group proportions, we'll use R's `prop.test()`, which tests the null hypothesis that the proportions in some number of groups are the same:\n\n$$\nH_0: \\theta = 0\n$$\n\nOur job with null hypothesis significance testing is to calculate a test statistic ($\\chi^2$ in this case) for $\\theta$, determine the probability of seeing that statistic in a world where $\\theta$ is actually 0, and infer whether the value we see could plausibly fit in a world where the null hypothesis is true. \n\nWe need to feed `prop.test()` either a matrix with a column of counts of successes (students who read comic books often) and failures (students who do not read comic books often) or two separate vectors: one of counts of successes (students who read comic books often) and one of counts of totals (all students). We'll do it both ways for fun.\n\nFirst we'll make a matrix of the counts of students from Mexico and the United States, with columns for the counts of those who read often and of those who don't read often.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_matrix <- reading_counts %>% \n  filter(book_type == \"Comic books\", frequency == \"Often\") %>% \n  mutate(n_not_often = total - n) %>% \n  select(n_often = n, n_not_often) %>% \n  as.matrix()\noften_matrix\n##      n_often n_not_often\n## [1,]   10605       27036\n## [2,]     524        4618\n```\n:::\n\n\nNow we can feed that to `prop.test()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprop.test(often_matrix)\n## \n## \t2-sample test for equality of proportions with continuity correction\n## \n## data:  often_matrix\n## X-squared = 759, df = 1, p-value <2e-16\n## alternative hypothesis: two.sided\n## 95 percent confidence interval:\n##  0.170 0.189\n## sample estimates:\n## prop 1 prop 2 \n##  0.282  0.102\n```\n:::\n\n\nThis gives us some helpful information. The \"flavor\" of the formal test is a \"2-sample test for equality of proportions with continuity correction\", which is fine, I guess. \n\n\n\n\n\nWe have proportions that are the same as what we have in the highlighted cells in the contingency table (28.17% / 10.19%) and we have 95% confidence interval for the difference. Oddly, R doesn't show the actual difference in these results, but we can see that difference if we use `model_parameters()` from [the {parameters} package](https://easystats.github.io/parameters/) (which is the apparent successor to `broom::tidy()`?). Here we can see that the difference in proportions is 18 percentage points:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprop.test(often_matrix) %>% \n  model_parameters()\n## 2-sample test for equality of proportions\n## \n## Proportion      | Difference |       95% CI | Chi2(1) |      p\n## --------------------------------------------------------------\n## 28.17% / 10.19% |     17.98% | [0.17, 0.19] |  759.26 | < .001\n## \n## Alternative hypothesis: two.sided\n```\n:::\n\n\nAnd finally we have a test statistic: a $\\chi^2$ value of 759.265, which is huge and definitely statistically significant. In a hypothetical world where there's no difference in the proportions, the probability of seeing a difference of at least 18 percentage points is super tiny (p < 0.001). We have enough evidence to confidently reject the null hypothesis and declare that the proportions of the groups are not the same. With the confidence interval, we can say that we are 95% confident that the interval 0.17–0.189 captures the true population parameter. We can't say that there's a 95% chance that the true value falls in this range—we can only talk about the range.\n\nWe can also do this without using a matrix by feeding `prop.test()` two vectors: one with counts of people who read comics often and one with counts of total respondents:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_values <- reading_counts %>% \n  filter(book_type == \"Comic books\", frequency == \"Often\")\n\n(n_often <- as.numeric(c(often_values[1, 4], often_values[2, 4])))\n## [1] 10605   524\n(n_respondents <- as.numeric(c(often_values[1, 5], often_values[2, 5])))\n## [1] 37641  5142\n\nprop.test(n_often, n_respondents)\n## \n## \t2-sample test for equality of proportions with continuity correction\n## \n## data:  n_often out of n_respondents\n## X-squared = 759, df = 1, p-value <2e-16\n## alternative hypothesis: two.sided\n## 95 percent confidence interval:\n##  0.170 0.189\n## sample estimates:\n## prop 1 prop 2 \n##  0.282  0.102\n```\n:::\n\n\nThe results are the same.\n\n\n## Bayesianly with Stan\n\n### Why Bayesian modeling?\n\nI don't like null hypotheses and I don't like flowcharts.\n\n::: {.column-margin}\n![](img/golem.jpg)\n\n[\"Golem\"](https://www.flickr.com/photos/botosynthetic/5837348219) by [smokeghost](https://www.flickr.com/people/botosynthetic/)\n\n:::\n\nRegular classical statistics classes teach about null hypotheses and flowcharts, but there's a better way. In his magisterial [*Statistical Rethinking*](https://xcelab.net/rm/statistical-rethinking/), Richard McElreath [describes how in legends people created mythological clay robots called golems that could protect cities from attacks](https://www.youtube.com/watch?v=cclUd_HoRlo), but that could also spin out of control and wreak all sorts of havoc. McElreaths uses the idea of golems as a metaphor for classical statistical models focused on null hypothesis significance testing, which also consist of powerful quasi-alchemical procedures that have to be followed precisely with specific flowcharts:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Statistical models as golems (slide 9 in [Statistical Rethinking 2022 Lecture 01](https://speakerdeck.com/rmcelreath/statistical-rethinking-2022-lecture-01?slide=9))](img/golem-flowchart.png){fig-align='center' width=100%}\n:::\n:::\n\n\nMcElreath argues that this golem-based approach to statistics is incredibly limiting, since (1) you have to choose the right test, and if it doesn't exist, you have to wait for some fancy statistician to invent it, and (2) you have to focus on rejecting null hypotheses instead of exploring research hypotheses.\n\nFor instance, in the null hypothesis framework section above, this was the actual question undergirding the analysis:\n\n> In a hypothetical world where $\\theta = 0$ (or where there's no difference between the proportions) what's the probability that this one-time collection of data fits in that world—and if the probability is low, is there enough evidence to confidently reject that hypothetical world of no difference?\n\noof. We set our `prop.test()` golem to work and got a p-value for the probability of seeing the 18 percentage point difference in a world where there's actually no difference. That p-value was low, so we confidently declared $\\theta$ to be statistically significant and not zero. But that was it. We rejected the null world. Yay. But that doesn't say much about our main research hypothesis. Boo.\n\nOur *actual* main question is far simpler:\n\n> Given the data here, what's the probability that there's no difference between the proportions, or that $\\theta \\neq 0$?\n\nBayesian-flavored statistics lets us answer this question and avoid null hypotheses and convoluted inference. Instead of calculating the probability of seeing some data given a null hypothesis ($P(\\text{Data} \\mid H_0)$), we can use [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference) to calculate the probability of a hypothesis given some data ($P(\\theta \\neq 0 \\mid \\text{Data})$).\n\n\n### Formal model\n\nSo instead of thinking about a specific statistical golem, we can think about modeling the data-generating process that could create the counts and proportions that we see in the PISA data.\n\nRemember that our data looks like this, with `n` showing a count of the people who read comic books often in each country and `total` showing a count of the people who responded to the question.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreading_counts %>% \n  filter(book_type == \"Comic books\", frequency == \"Often\")\n## # A tibble: 2 × 6\n##   country       book_type   frequency     n total  prop\n##   <fct>         <chr>       <fct>     <int> <int> <dbl>\n## 1 Mexico        Comic books Often     10605 37641 0.282\n## 2 United States Comic books Often       524  5142 0.102\n```\n:::\n\n\nThe actual process for generating that `n` involved asking thousands of individual, independent people if they read comic books often. If someone says yes, it's counted as a \"success\" (or marked as \"often\"); if they say no, it's not marked as \"often\". It's a binary choice repeated across thousands of independent questions, or \"trials.\" There's also an underlying overall probability for reporting \"often,\" which corresponds to the proportion of people selecting it.\n\nThe official statistical term for this kind of data-generating processes (a bunch of independent trials with some probability of success) is a [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution), and it's defined like this, with three parameters:\n\n$$\ny \\sim \\operatorname{Binomial}(n, \\pi)\n$$\n\n1. Number of successes ($y$: the number of people responding yes to \"often,\" or `n` in our data\n2. Probability of success ($\\pi$): the probability someone says yes to \"often,\" or the thing we want to model for each country\n3. Number of trials ($n$): the total number of people asked the question, or `total` in our data\n\nThe number of successes and trials are just integers—they're counts—and we already know those, since they're in the data. The probability of success $\\pi$ is a percentage and ranges somewhere between 0 and 1. We don't know this value, but we can estimate it with Bayesian methods by defining a prior and a likelihood, churning through a bunch of Monte Carlo Markov Chain (MCMC) simulations, and finding a posterior distribution of $\\pi$.\n\nWe can use a Beta distribution to model $\\pi$, since Beta distributions are naturally bound between 0 and 1 and they work well for probability-scale things. Beta distributions are defined by two parameters: (1) $\\alpha$ or $a$ or `shape1` in R and (2) $\\beta$ or $b$ or `shape2` in R. [See this section of my blog post](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#beta-distributions-and-shape-parameters) on zero-inflated Beta regression for way more details about how these parameters work and what they mean.\n\nSuper quickly, we're interested in the probability of a \"success\" (or where \"often\" is yes), which is the number of \"often\"s divided by the total number of responses:\n\n$$\n\\frac{\\text{Number of successes}}{\\text{Number of trials}}\n$$\n\nor\n\n$$\n\\frac{\\text{Number of often = yes}}{\\text{Number of responses}}\n$$\n\nWe can separate that denominator into two parts:\n\n$$\n\\frac{\\text{Number of often = yes}}{(\\text{Number of often = yes}) + (\\text{Number of often } \\neq \\text{yes})}\n$$\n\nThe $\\alpha$ and $\\beta$ parameters correspond to the counts of successes and failures::\n\n$$\n\\frac{\\alpha}{\\alpha + \\beta}\n$$\n\nWith these two shape parameters, we can create any percentage or fraction we want. We can also control the uncertainty of the distribution by tinkering with the scale of the parameters. For instance, if we think there's a 40% chance of something happening, this could be represented with $\\alpha = 4$ and $\\beta = 6$, since $\\frac{4}{4 + 6} = 0.4$. We could also write it as $\\alpha = 40$ and $\\beta = 60$, since $\\frac{40}{40 + 60} = 0.4$ too. Both are centered at 40%, but Beta(40, 60) is a lot narrower and less uncertain.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot() +\n  stat_function(fun = ~dbeta(., 4, 6), geom = \"area\",\n                aes(fill = \"Beta(4, 6)\"), alpha = 0.5) +\n  stat_function(fun = ~dbeta(., 40, 60), geom = \"area\",\n                aes(fill = \"Beta(40, 60)\"), alpha = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  scale_fill_manual(values = c(\"Beta(4, 6)\" = \"#FFDC00\",\n                               \"Beta(40, 60)\" = \"#F012BE\")) +\n  labs(x = \"π\", y = NULL, fill = NULL) +\n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![Beta(4, 6) and Beta(40, 60) distributions](index_files/figure-html/plot-beta-example-1.png){fig-align='center' fig-alt='Beta(4, 6) and Beta(40, 60) distributions' width=90%}\n:::\n:::\n\n\nWe've already seen the data and know that the proportion of students who read comic books often is 10ish% in the United States and 30ish% in Mexico, but we'll cheat and say that we think that around 25% of students read comic books often, ± some big amount. This implies something like a Beta(2, 6) distribution (since $\\frac{2}{2+6} = 0.25$), with lots of low possible values, but not a lot of $\\pi$s are above 50%. We could narrow this down by scaling up the parameters (like Beta(20, 60) or Beta(10, 40), etc.), but leaving the prior distribution of $\\pi$ wide like this allows for more possible responses (maybe 75% of students in one country read comic books often!).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot() +\n  stat_function(fun = ~dbeta(., 2, 6), geom = \"area\", fill = \"#AC3414\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Possible values for π\", y = NULL, fill = NULL) +\n  theme_nice() +\n  theme(axis.text.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Prior distribution for π using Beta(2, 6)](index_files/figure-html/plot-beta-prior-1.png){fig-align='center' fig-alt='Prior distribution for π using Beta(2, 6)' width=90%}\n:::\n:::\n\n\nOkay, so with our Beta(2, 6) prior, we now have all the information we need to specify the official formal model of the data generating process for our estimand $\\theta$ without any flowchart golems or null hypotheses:\n\n$$\n\\begin{aligned}\n&\\ \\textbf{Estimand} \\\\\n\\theta =&\\ \\pi_{\\text{comic books, often}_\\text{Mexico}} - \\pi_{\\text{comic books, often}_\\text{US}} \\\\[10pt]\n&\\ \\textbf{Beta-binomial model for Mexico} \\\\\ny_{n \\text{ comic books, often}_\\text{Mexico}} \\sim&\\ \\operatorname{Binomial}(n_{\\text{Total students}_\\text{Mexico}}, \\pi_{\\text{comic books, often}_\\text{Mexico}}) \\\\\n\\pi_{\\text{comic books, often}_\\text{Mexico}} \\sim&\\ \\operatorname{Beta}(\\alpha_\\text{Mexico}, \\beta_\\text{Mexico}) \\\\[10pt]\n&\\ \\textbf{Beta-binomial model for the United States} \\\\\ny_{n \\text{ comic books, often}_\\text{US}} \\sim&\\ \\operatorname{Binomial}(n_{\\text{Total students}_\\text{US}}, \\pi_{\\text{comic books, often}_\\text{US}}) \\\\\n\\pi_{\\text{comic books, often}_\\text{US}} \\sim&\\ \\operatorname{Beta}(\\alpha_\\text{US}, \\beta_\\text{US}) \\\\[10pt]\n&\\ \\textbf{Priors} \\\\\n\\alpha_\\text{Mexico}, \\alpha_\\text{US} =&\\ 2 \\\\\n\\beta_\\text{Mexico}, \\beta_\\text{US} =&\\ 6\n\\end{aligned}\n$$\n\n\n### Basic Stan model\n\nThe neat thing about Stan is that it translates fairly directly from this mathematical model notation into code. Here we'll define three different blocks in a Stan program: \n\n1. Data that gets fed into the model, or the counts of respondents (or $y$ and $n$)\n2. Parameters to estimate, or $\\pi_\\text{US}$ and $\\pi_\\text{Mexico}$\n3. The prior and model for estimating those parameters, or $\\operatorname{Beta}(2, 6)$ and $y \\sim \\operatorname{Binomial}(n, \\pi)$\n\n```{.stan, eval=FALSE, output.var=\"\", filename=\"props-basic.stan\"}\n// Stuff from R\ndata {\n  int<lower=0> often_us;\n  int<lower=0> total_us;\n  int<lower=0> often_mexico;\n  int<lower=0> total_mexico;\n}\n\n// Things to estimate\nparameters {\n  real<lower=0, upper=1> pi_us;\n  real<lower=0, upper=1> pi_mexico;\n}\n\n// Prior and likelihood\nmodel {\n  pi_us ~ beta(2, 6);\n  pi_mexico ~ beta(2, 6);\n  \n  often_us ~ binomial(total_us, pi_us);\n  often_mexico ~ binomial(total_mexico, pi_mexico);\n}\n```\n\nUsing {cmdstanr} as our interface with Stan, we first have to compile the script into an executable file:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/compile-model-props-basic_611b8c114f9693dcd69bfc840276b606'}\n\n```{.r .cell-code}\nmodel_props_basic <- cmdstan_model(\"props-basic.stan\")\n```\n:::\n\n\nWe can then feed it a list of data and run a bunch of MCMC chains:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_values <- reading_counts %>% \n  filter(book_type == \"Comic books\", frequency == \"Often\")\n\n(n_often <- as.numeric(c(often_values[1, 4], often_values[2, 4])))\n## [1] 10605   524\n(n_respondents <- as.numeric(c(often_values[1, 5], often_values[2, 5])))\n## [1] 37641  5142\n\nprops_basic_samples <- model_props_basic$sample(\n  data = list(often_us = n_often[2],\n              total_us = n_respondents[2],\n              often_mexico = n_often[1],\n              total_mexico = n_respondents[1]),\n  chains = CHAINS, iter_warmup = WARMUP, iter_sampling = (ITER - WARMUP), seed = BAYES_SEED,\n  refresh = 0\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n\nprops_basic_samples$print(\n  variables = c(\"pi_us\", \"pi_mexico\"), \n  \"mean\", \"median\", \"sd\", ~quantile(.x, probs = c(0.025, 0.975))\n)\n##   variable mean median   sd 2.5% 97.5%\n##  pi_us     0.10   0.10 0.00 0.09  0.11\n##  pi_mexico 0.28   0.28 0.00 0.28  0.29\n```\n:::\n\n\nWe have the two proportions—10% and 28%—and they match what we found in the original table and in the frequentist `prop.test()` results (yay!). Let's visualize these things:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprops_basic_samples %>% \n  gather_draws(pi_us, pi_mexico) %>% \n  ggplot(aes(x = .value, y = .variable, fill = .variable)) +\n  stat_halfeye() +\n  # Multiply axis limits by 1.5% so that the right \"%\" isn't cut off\n  scale_x_continuous(labels = label_percent(), expand = c(0, 0.015)) +\n  scale_fill_manual(values = c(clr_usa, clr_mex)) +\n  guides(fill = \"none\") +\n  labs(x = \"Proportion of students who read comic books often\",\n       y = NULL) +\n  theme_nice()\n```\n\n::: {.cell-output-display}\n![Posterior distributions of the proportion of students who read comic books often in the United States and Mexico](index_files/figure-html/plot-props-basic-stan-1.png){fig-align='center' fig-alt='Posterior distributions of the proportion of students who read comic books often in the United States and Mexico' width=90%}\n:::\n:::\n\n\nThis plot is neat for a couple reasons. First it shows the difference in variance across these two distributions. The sample size for Mexican respondents is huge, so the average is a lot more precise and <span style=\"color: #57643C\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>the distribution</span> is narrower than <span style=\"color: #127088\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>the American one</span>. Second, by just eyeballing the plot we can see that there's definitely no overlap between the two distributions, which implies that <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>the difference (θ) between the two</span> is definitely not zero—Mexican respondents are way more likely than Americans to read comic books often. We can find <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>that difference</span> by taking the pairwise difference between the two with `compare_levels()` from {tidybayes}, which subtracts one group's posterior from the other:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbasic_diffs <- props_basic_samples %>% \n  gather_draws(pi_us, pi_mexico) %>% \n  ungroup() %>% \n  # compare_levels() subtracts things using alphabetical order, so by default it\n  # would calculate pi_us - pi_mexico, but we want the opposite, so we have to\n  # make pi_us the first level\n  mutate(.variable = fct_relevel(.variable, \"pi_us\")) %>% \n  compare_levels(.value, by = .variable, comparison = \"pairwise\")\n\nbasic_diffs %>% \n  ggplot(aes(x = .value)) +\n  stat_halfeye(fill = clr_diff) +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Posterior distribution of the difference in proportions of students who read comic books often in the United States and Mexico](index_files/figure-html/plot-diffs-basic-stan-1.png){fig-align='center' fig-alt='Posterior distribution of the difference in proportions of students who read comic books often in the United States and Mexico' width=90%}\n:::\n:::\n\n\nWe can also do some Bayesian inference and find the probability that <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>that difference between the two groups</span> is greater than 0 (or a kind of Bayesian p-value, but way more logical than null hypothesis p-values). We can calculate how many posterior draws are bigger than 0 and divide that by the number of draws to get the official proportion.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbasic_diffs %>% \n  summarize(median = median_qi(.value),\n            p_gt_0 = sum(.value > 0) / n()) %>% \n  unnest(median)\n## # A tibble: 1 × 8\n##   .variable             y  ymin  ymax .width .point .interval p_gt_0\n##   <chr>             <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>      <dbl>\n## 1 pi_mexico - pi_us 0.180 0.170 0.189   0.95 median qi             1\n```\n:::\n\n\nThere's a 100% chance that <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>that difference</span> is not zero, or a 100% chance that Mexican respondents are way more likely than their American counterparts to read comic books often. \n\n### Stan model improvements\n\nThis basic Stan model is neat, but we can do a couple things to make it better:\n\n1. Right now we have to feed it 4 separate numbers (counts and totals for the US and Mexico). It would be nice to just feed it a vector of counts and a vector of totals (or even a whole matrix like we did with `prop.test()`).\n2. Right now we have to manually calculate the difference between the two groups (0.28 − 0.10). It would be nice to have Stan do that work for us.\n\nWe'll tackle each of these issues in turn.\n\nFirst we'll change how the script handles the data so that it's more dynamic. Now instead of defining explicit variables and parameters as `total_us` or `pi_mexico` or whatever, we'll use arrays and vectors so that we can use any arbitrary number of groups if we want:\n\n```{.stan, eval=FALSE, output.var=\"\", filename=\"props-better.stan\"}\n// Stuff from R\ndata {\n  int<lower=0> n;\n  array[n] int<lower=0> often;\n  array[n] int<lower=0> total;\n}\n\n// Things to estimate\nparameters {\n  vector<lower=0, upper=1>[n] pi;\n}\n\n// Prior and likelihood\nmodel {\n  pi ~ beta(2, 6);\n  \n  // We could specify separate priors like this\n  // pi[1] ~ beta(2, 6);\n  // pi[2] ~ beta(2, 6);\n  \n  often ~ binomial(total, pi);\n}\n```\n\nLet's make sure it works. Note how we now have to feed it an `n` for the number of countries and vectors of counts for `often` and `total`:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/compile-model-props-better_8c7224c29a297bd6939250a580c0c3e9'}\n\n```{.r .cell-code}\nmodel_props_better <- cmdstan_model(\"props-better.stan\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprops_better_samples <- model_props_better$sample(\n  data = list(n = 2,\n              often = c(n_often[2], n_often[1]),\n              total = c(n_respondents[2], n_respondents[1])),\n  chains = CHAINS, iter_warmup = WARMUP, iter_sampling = (ITER - WARMUP), seed = BAYES_SEED,\n  refresh = 0\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n\nprops_better_samples$print(\n  variables = c(\"pi[1]\", \"pi[2]\"), \n  \"mean\", \"median\", \"sd\", ~quantile(.x, probs = c(0.025, 0.975))\n)\n##  variable mean median   sd 2.5% 97.5%\n##     pi[1] 0.10   0.10 0.00 0.09  0.11\n##     pi[2] 0.28   0.28 0.00 0.28  0.29\n```\n:::\n\n\n\n\nIt worked and the results are the same! The parameter names are now <span style=\"color: #127088\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>\"`pi[1]`\"</span> and <span style=\"color: #57643C\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>\"`pi[2]`\"</span> and we're responsible for keeping track of which subscripts correspond to which countries, which is annoying, but that's Stan :shrug:.\n\nFinally, we can modify the script a little more to automatically calculate <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>θ</span>. We'll add a `generated quantities` block for that:\n\n```{.stan, eval=FALSE, output.var=\"\", filename=\"props-best.stan\"}\n// Stuff from R\ndata {\n  int<lower=0> n;\n  array[n] int<lower=0> often;\n  array[n] int<lower=0> total;\n}\n\n// Things to estimate\nparameters {\n  vector<lower=0, upper=1>[n] pi;\n}\n\n// Prior and likelihood\nmodel {\n  pi ~ beta(2, 6);\n  \n  often ~ binomial(total, pi);\n}\n\n// Stuff Stan will calculate before sending back to R\ngenerated quantities {\n  real theta;\n  theta = pi[2] - pi[1];\n}\n```\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/compile-model-props-best_c6f4b5d4e530b45e256147a3ce15f7eb'}\n\n```{.r .cell-code}\nmodel_props_best <- cmdstan_model(\"props-best.stan\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprops_best_samples <- model_props_best$sample(\n  data = list(n = 2,\n              often = c(n_often[2], n_often[1]),\n              total = c(n_respondents[2], n_respondents[1])),\n  chains = CHAINS, iter_warmup = WARMUP, iter_sampling = (ITER - WARMUP), seed = BAYES_SEED,\n  refresh = 0\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n\nprops_best_samples$print(\n  variables = c(\"pi[1]\", \"pi[2]\", \"theta\"), \n  \"mean\", \"median\", \"sd\", ~quantile(.x, probs = c(0.025, 0.975))\n)\n##  variable mean median   sd 2.5% 97.5%\n##     pi[1] 0.10   0.10 0.00 0.09  0.11\n##     pi[2] 0.28   0.28 0.00 0.28  0.29\n##     theta 0.18   0.18 0.00 0.17  0.19\n```\n:::\n\n\nCheck that out! Stan returned our <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>18 percentage point difference</span> and we didn't need to use `compare_levels()`! We can plot it directly:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Raw Stan doesn't preserve the original country names or order, so we have to\n# do a bunch of reversing and relabeling on our own here\np1 <- props_best_samples %>% \n  spread_draws(pi[i]) %>% \n  mutate(i = factor(i)) %>% \n  ggplot(aes(x = pi, y = fct_rev(i), fill = fct_rev(i))) +\n  stat_halfeye() +\n  # Multiply axis limits by 1.5% so that the right \"%\" isn't cut off\n  scale_x_continuous(labels = label_percent(), expand = c(0, 0.015)) +\n  scale_y_discrete(labels = rev(c(\"United States\", \"Mexico\"))) +\n  scale_fill_manual(values = c(clr_usa, clr_mex)) +\n  guides(fill = \"none\") +\n  labs(x = \"Proportion of students who read comic books often\",\n       y = NULL) +\n  theme_nice()\n\np2 <- props_best_samples %>% \n  spread_draws(theta) %>% \n  ggplot(aes(x = theta)) +\n  stat_halfeye(fill = clr_diff) +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank())\n\n(p1 / plot_spacer() / p2) + \n  plot_layout(heights = c(0.785, 0.03, 0.185))\n```\n\n::: {.cell-output-display}\n![Posterior distribution of the proportions and difference in proportions of students who read comic books often in the United States and Mexico; results from raw Stan code](index_files/figure-html/plot-diffs-best-stan-1.png){fig-align='center' fig-alt='Posterior distribution of the proportions and difference in proportions of students who read comic books often in the United States and Mexico; results from raw Stan code' width=90%}\n:::\n:::\n\n\n\n## Bayesianly with {brms}\n\nWorking with raw Stan code like that is fun and exciting—understanding the inner workings of these models is really neat and important! But in practice, I rarely use raw Stan. It takes too much pre- and post-processing for my taste (the data has to be fed in a list instead of a nice rectangular data frame; the variable names get lost unless you do some extra programming work; etc.). \n\nInstead, I use [{brms}](https://paul-buerkner.github.io/brms/) for pretty much all my Bayesian models. It uses R's familiar formula syntax, it works with regular data frames, it maintains variable names, and it's just an all-around super-nice-and-polished frontend for working with Stan.\n\nWith a little formula finagling, we can create the same beta binomial model we built with raw Stan using {brms}\n\n### Counts and trials as formula outcomes\n\nIn R's standard formula syntax, you put the outcome on the left-hand side of a `~` and the explanatory variables on the right-hand side: \n\n```r\nlm(y ~ x, data = whatever)\n```\n\nYou typically feed the model function a data frame with columns for each of the variables included. One neat and underappreciated feature of the `glm()` function is that you can feed function aggregated count data (instead of long data with lots of rows) by specifying the number of successes and the total number of failures as the outcome part of the formula. This runs something called aggregated logistic regression or aggregated binomial regression.\n\n```r\nglm(cbind(n_successes, n_failures) ~ x, data = whatever, family = binomial)\n```\n\n{brms} uses slightly different syntax for [aggregated logistic regression](https://bookdown.org/content/4857/god-spiked-the-integers.html#binomial-regression). Instead of the number of failures, it needs the total number of trials, and it doesn't use `cbind(...)`—it uses `n | trials(total)`, like this:\n\n```r\nbrm(\n  bf(n | trials(total) ~ x)\n  data = whatever,\n  family = binomial\n)\n```\n\nOur comic book data is already in this count form, and we have columns for the number of \"successes\" (number of respondents reading comic books often) and the total number of \"trials\" (number of respondents reading comic books):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_comics_only <- reading_counts %>% \n  filter(book_type == \"Comic books\", frequency == \"Often\")\noften_comics_only\n## # A tibble: 2 × 6\n##   country       book_type   frequency     n total  prop\n##   <fct>         <chr>       <fct>     <int> <int> <dbl>\n## 1 Mexico        Comic books Often     10605 37641 0.282\n## 2 United States Comic books Often       524  5142 0.102\n```\n:::\n\n\n### Binomial model with logistic link\n\nSince we have columns for `n`, `total`, and `country`, we can run an aggregated binomial logistic regression model like this:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/q1-model-logit_105d96c0271d8fb2ad7a03232f588f23'}\n\n```{.r .cell-code}\noften_comics_model_logit <- brm(\n  bf(n | trials(total) ~ country),\n  data = often_comics_only,\n  family = binomial(link = \"logit\"),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0\n)\n## ld: warning: duplicate -rpath '/Users/andrew/.cmdstan/cmdstan-2.33.1/stan/lib/stan_math/lib/tbb' ignored\n## Start sampling\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_comics_model_logit\n##  Family: binomial \n##   Links: mu = logit \n## Formula: n | trials(total) ~ country \n##    Data: often_comics_only (Number of observations: 2) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept              -0.94      0.01    -0.96    -0.91 1.00     4706     3051\n## countryUnitedStates    -1.24      0.05    -1.34    -1.15 1.00      981     1123\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nBecause we used a logit link for the binomial family, these results are on the log odds scale, which, ew. We can't really interpret them directly unless we do some extra math with `plogis()` ([see here for more about how to do that](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#fractional-logistic-regression)). The logistic-ness of the results is also apparent in the formal mathy model for this approach, which no longer uses a Beta distribution for estimating $\\pi$:\n\n$$\n\\begin{aligned}\ny_{n \\text{ comic books, often}} \\sim&\\ \\operatorname{Binomial}(n_{\\text{Total students}}, \\pi_{\\text{comic books, often}}) \\\\\n\\operatorname{logit}(\\pi_{\\text{comic books, often}}) =&\\ \\beta_0 + \\beta_1 \\text{United States} \\\\[5pt]\n\\beta_0, \\beta_1 =& \\text{Whatever brms uses as default priors}\\\\\n\\end{aligned}\n$$\n\nWe can still work with percentage point values if we use `epred_draws()` and a bit of data wrangling, since that automatically back-transforms $\\operatorname{logit}(\\pi)$ from log odds to counts ([see here for an explanation of how and why](https://www.andrewheiss.com/blog/2022/09/26/guide-visualizing-types-posteriors/)). We can convert these posterior counts to a proportion again by dividing each predicted count by the total for each row.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# brms keeps all the original factor/category names, so there's no need for\n# extra manual work here!\ndraws_logit <- often_comics_model_logit %>% \n  # This gives us counts...\n  epred_draws(newdata = often_comics_only) %>% \n  # ...so divide by the original total to get proportions again\n  mutate(.epred_prop = .epred / total)\n\np1 <- draws_logit %>% \n  ggplot(aes(x = .epred_prop, y = country, fill = country)) +\n  stat_halfeye() +\n  scale_x_continuous(labels = label_percent(), expand = c(0, 0.015)) +\n  scale_fill_manual(values = c(clr_usa, clr_mex)) +\n  guides(fill = \"none\") +\n  labs(x = \"Proportion of students who read comic books often\",\n       y = NULL) +\n  theme_nice()\n\np2 <- draws_logit %>% \n  ungroup() %>% \n  # compare_levels() subtracts things using alphabetical order, so so we have to\n  # make the United States the first level\n  mutate(country = fct_relevel(country, \"United States\")) %>% \n  compare_levels(.epred_prop, by = \"country\") %>% \n  ggplot(aes(x = .epred_prop)) +\n  stat_halfeye(fill = clr_diff) +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  # Make it so the pointrange doesn't get cropped\n  coord_cartesian(clip = \"off\") + \n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank())\n\n(p1 / plot_spacer() / p2) + \n  plot_layout(heights = c(0.785, 0.03, 0.185))\n```\n\n::: {.cell-output-display}\n![Posterior distribution of the proportions and difference in proportions of students who read comic books often in the United States and Mexico; results from logistic regression model in {brms}](index_files/figure-html/q1-plot-logit-1.png){fig-align='center' fig-alt='Posterior distribution of the proportions and difference in proportions of students who read comic books often in the United States and Mexico; results from logistic regression model in {brms}' width=90%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws_logit %>% \n  group_by(country) %>% \n  median_qi(.epred_prop)\n## # A tibble: 2 × 7\n##   country       .epred_prop .lower .upper .width .point .interval\n##   <fct>               <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 Mexico              0.282 0.277   0.286   0.95 median qi       \n## 2 United States       0.102 0.0936  0.110   0.95 median qi\n```\n:::\n\n\nCool cool, all the results are the same as using raw Stan.\n\n\n### Binomial model with identity link\n\nWe didn't set any priors here, and if we want to be good Bayesians, we should. However, given the logit link, we'd need to specify priors on the log odds scale, and I can't naturally think in logits. I *can* think about percentages though, which is why I like the Beta distribution for priors for proportions—it just makes sense.\n\nAlso, the raw Stan models spat out percentage-point scale parameters—it'd be neat if {brms} could too.\n\nAnd it can! We just have to change the link function for the binomial family from `\"logit\"` to `\"identity\"`. This isn't really documented anywhere (I don't think?), and it feels weird and wrong, but it works. Note how we take the \"logit\" out of the second line of the model—we're no longer using a link function:\n\n$$\n\\begin{aligned}\ny_{n \\text{ comic books, often}} \\sim&\\ \\operatorname{Binomial}(n_{\\text{Total students}}, \\pi_{\\text{comic books, often}}) \\\\\n\\pi_{\\text{comic books, often}} =&\\ \\beta_0 + \\beta_1 \\text{United States} \\\\[5pt]\n\\beta_0, \\beta_1 =&\\ \\text{Whatever brms uses as default priors}\\\\\n\\end{aligned}\n$$\n\nDoing this works, but there are some issues. The identity link in a binomial model means that the model parameters won't be transformed to the logit scale and will instead stay on the proportion scale. We'll get some errors related to MCMC values because the outcome needs to be constrained between 0 and 1, and the MCMC chains will occasionally wander down into negative numbers and make Stan mad. The model will mostly fit if we specify initial MCMC values at 0.1 or something, but it'll still complain.\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/q1-model-identity-intercept_d458efc5dd70eb13546b610c258af07d'}\n\n```{.r .cell-code}\noften_comics_model_identity <- brm(\n  bf(n | trials(total) ~ country),\n  data = often_comics_only,\n  family = binomial(link = \"identity\"),\n  init = 0.1,\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0\n)\n## ld: warning: duplicate -rpath '/Users/andrew/.cmdstan/cmdstan-2.33.0/stan/lib/stan_math/lib/tbb' ignored\n## Start sampling\n## Running MCMC with 4 parallel chains...\n## Chain 3 Rejecting initial value:\n## Chain 3   Error evaluating the log probability at the initial value.\n## Chain 3 Exception: binomial_lpmf: Probability parameter[1] is -0.0175658, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 3 Exception: binomial_lpmf: Probability parameter[1] is -0.0175658, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 3 Rejecting initial value:\n## Chain 3   Error evaluating the log probability at the initial value.\n## Chain 3 Exception: binomial_lpmf: Probability parameter[1] is -0.0471304, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 3 Exception: binomial_lpmf: Probability parameter[1] is -0.0471304, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 3 Rejecting initial value:\n## Chain 3   Error evaluating the log probability at the initial value.\n## Chain 3 Exception: binomial_lpmf: Probability parameter[2] is -0.03896, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 3 Exception: binomial_lpmf: Probability parameter[2] is -0.03896, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 3 Rejecting initial value:\n## Chain 3   Error evaluating the log probability at the initial value.\n## Chain 3 Exception: binomial_lpmf: Probability parameter[1] is -0.0529492, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 3 Exception: binomial_lpmf: Probability parameter[1] is -0.0529492, but must be in the interval [0, 1] (in '/var/folders/17/g3pw3lvj2h30gwm67tbtx98c0000gn/T/RtmpqXVrXl/model-2ca815c60095.stan', line 36, column 4 to column 44)\n## Chain 2 finished in 0.0 seconds.\n## Chain 1 finished in 0.1 seconds.\n## Chain 3 finished in 0.1 seconds.\n## Chain 4 finished in 0.1 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.1 seconds.\n## Total execution time: 0.3 seconds.\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_comics_model_identity\n##  Family: binomial \n##   Links: mu = identity \n## Formula: n | trials(total) ~ country \n##    Data: often_comics_only (Number of observations: 2) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept               0.28      0.00     0.28     0.29 1.00     3627     2558\n## countryUnitedStates    -0.18      0.00    -0.19    -0.17 1.00     1472     1907\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nOne really nice thing about this identity-link model is that the coefficient for `countryUnitedStates` shows us the percentage-point-scale difference in proportions: −0.18! This is just a regular regression model, so the intercept shows us the average proportion when United States is false (i.e. for Mexico), and the United States coefficient shows the offset from the intercept.\n\nWorking with the `countryUnitedStates` coefficient directly is convenient—there's no need to divide predicted values by totals or use `compare_levels()` to find the difference between the United States and Mexico. We have <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>our estimand</span> immediately.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws_diffs_identity <- often_comics_model_identity %>% \n  gather_draws(b_countryUnitedStates) %>% \n  # Reverse the value since our theta is Mexico - US, not US - Mexico\n  mutate(.value = -.value)\n\ndraws_diffs_identity %>% \n  ggplot(aes(x = .value)) +\n  stat_halfeye(fill = clr_diff) +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Posterior distribution of the difference in proportions of students who read comic books often in the United States and Mexico; results from binomial model with identity link in {brms}](index_files/figure-html/q1-plot-model-identity-intercept-1.png){fig-align='center' fig-alt='Posterior distribution of the difference in proportions of students who read comic books often in the United States and Mexico; results from binomial model with identity link in {brms}' width=90%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws_diffs_identity %>% \n  median_qi(.value)\n## # A tibble: 1 × 7\n##   .variable             .value .lower .upper .width .point .interval\n##   <chr>                  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 b_countryUnitedStates  0.180  0.170  0.189   0.95 median qi\n```\n:::\n\n\n### Intercept-free binomial model with identity link\n\nHowever, I'm still not entirely happy with it. For one thing, I don't like all the initial MCMC errors. The model still eventually fit, but I'd prefer it to have a less rocky start. I could probably tinker with more options to get it working, but that's a hassle.\n\nMore importantly, though, is the issue of priors. We still haven't set any. Also, we're no longer using a beta-binomial model—this is just regular old logistic regression, which means we're working with intercepts and slopes. If we use the `n | trials(total) ~ country` model with an identity link, we'd need to set priors for the intercept and for the difference, which means we need to think about two types of values: (1) the prior average percentage for Mexico and (2) the prior average difference between Mexico and the United States. In the earlier raw Stan model, we set priors for the average percentages for each country and didn't worry about thinking about the difference. Conceptually, I think this is easier. In my own work, I can think about the prior distributions for specific survey response categories (30% might agree, 50% might disagree, 20% might be neutral), but thinking about differences is less natural and straightforward (there might be a 20 percentage point difference between agree and disagree? that feels weird).\n\nTo get percentages for each country *and* avoid the odd initial value errors *and* set more natural priors, and ultimately use a beta-binomial model, we can fit an intercept-free model by including a 0 in the right-hand side of the formula. This disables the Mexico reference category and returns estimates for both Mexico and the United States. Now we can finally set a prior too. Here, as I did with the Stan model earlier, I use Beta(2, 6) for both countries, but it could easily be different for each country too. This is one way to force {brms} to essentially use a beta-binomial model, and results in something like this:\n\n\n$$\n\\begin{aligned}\ny_{n \\text{ comic books, often}} \\sim&\\ \\operatorname{Binomial}(n_{\\text{Total students}}, \\pi_{\\text{comic books, often}}) \\\\\n\\pi_{\\text{comic books, often}} =&\\ \\beta_\\text{Mexico} + \\beta_\\text{United States} \\\\[10pt]\n\\beta_\\text{Mexico}, \\beta_\\text{United States} =&\\ \\operatorname{Beta}(2, 6)\\\\\n\\end{aligned}\n$$\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/q1-model-identity_ec1b65363b71270e1f5405f8370c7732'}\n\n```{.r .cell-code}\noften_comics_model <- brm(\n  bf(n | trials(total) ~ 0 + country),\n  data = often_comics_only,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(2, 6), class = b, lb = 0, ub = 1)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0\n)\n## ld: warning: duplicate -rpath '/Users/andrew/.cmdstan/cmdstan-2.33.0/stan/lib/stan_math/lib/tbb' ignored\n## Start sampling\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.1 seconds.\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_comics_model\n##  Family: binomial \n##   Links: mu = identity \n## Formula: n | trials(total) ~ 0 + country \n##    Data: often_comics_only (Number of observations: 2) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## countryMexico           0.28      0.00     0.28     0.29 1.00     3581     2914\n## countryUnitedStates     0.10      0.00     0.09     0.11 1.00     2824     2470\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nThe coefficients here represent the average proportions for each country. The <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>main estimand we care about</span> is still the difference between the two, so we need to do a little bit of data manipulation to calculate that, just like we did with the first logit version of the model:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- often_comics_model %>% \n  epred_draws(newdata = often_comics_only) %>% \n  mutate(.epred_prop = .epred / total) %>% \n  ggplot(aes(x = .epred_prop, y = country, fill = country)) +\n  stat_halfeye() +\n  scale_x_continuous(labels = label_percent(), expand = c(0, 0.015)) +\n  scale_fill_manual(values = c(clr_usa, clr_mex)) +\n  guides(fill = \"none\") +\n  labs(x = \"Proportion of students who read comic books often\",\n       y = NULL) +\n  theme_nice()\n\np2 <- often_comics_model %>% \n  epred_draws(newdata = often_comics_only) %>% \n  mutate(.epred_prop = .epred / total) %>% \n  ungroup() %>% \n  # compare_levels() subtracts things using alphabetical order, so so we have to\n  # make the United States the first level\n  mutate(country = fct_relevel(country, \"United States\")) %>% \n  compare_levels(.epred_prop, by = country,\n                 comparison = \"pairwise\") %>% \n  ggplot(aes(x = .epred_prop)) +\n  stat_halfeye(fill = clr_diff) +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  # Make it so the pointrange doesn't get cropped\n  coord_cartesian(clip = \"off\") + \n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank())\n\n(p1 / plot_spacer() / p2) + \n  plot_layout(heights = c(0.785, 0.03, 0.185))\n```\n\n::: {.cell-output-display}\n![Posterior distribution of the proportions and difference in proportions of students who read comic books often in the United States and Mexico; results from an intercept-free binomial model with identity link in {brms}](index_files/figure-html/q1-plot-model-identity-1.png){fig-align='center' fig-alt='Posterior distribution of the proportions and difference in proportions of students who read comic books often in the United States and Mexico; results from an intercept-free binomial model with identity link in {brms}' width=90%}\n:::\n:::\n\n\n### Actual beta-binomial model\n\nUntil {brms} 2.17, there wasn't an official beta-binomial distribution for {brms}, but it was used as [the example for creating your own custom family](https://cran.r-project.org/web/packages/brms/vignettes/brms_customfamilies.html). It is now implemented in {brms} and allows you to define both a mean ($\\mu$) and precision ($\\phi$) for a Beta distribution, just like {brms}'s other Beta-related models (like zero-inflated, etc.—[see here for a lot more about those](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/)). This means that we can model both parts of the distribution simultaneously, which is neat, since it allows us to deal with potential overdispersion in outcomes.  [Paul Bürkner's original rationale for not including it](https://discourse.mc-stan.org/t/beta-binomial-why-not-a-default-family-in-the-package/10625/2) was that a regular binomial model with a random effect for the observation id also allows you to account for overdispersion, so there's not really a need for an official beta-binomial family. [But in March 2022](https://github.com/paul-buerkner/brms/pull/1319) the `beta_binomial` family was added as an official distributional family, which is neat.\n\nWe can use it here instead of `family = binomial(link = \"identity\")` with a few adjustments. The family uses a different mean/precision parameterization of the Beta distribution instead of the two shapes $\\alpha$ and $\\beta$, but we can switch between them with some algebra ([see this for more details](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#mean-and-precision-instead-of-shapes)):\n\n$$\n\\begin{equation}\n\\begin{aligned}[t]\n\\text{Shape 1:} && \\alpha &= \\mu \\phi \\\\\n\\text{Shape 2:} && \\beta &= (1 - \\mu) \\phi\n\\end{aligned}\n\\qquad\\qquad\\qquad\n\\begin{aligned}[t]\n\\text{Mean:} && \\mu &= \\frac{\\alpha}{\\alpha + \\beta} \\\\\n\\text{Precision:} && \\phi &= \\alpha + \\beta\n\\end{aligned}\n\\end{equation}\n$$\n\nBy default, $\\mu$ is modeled on the log odds scale and $\\phi$ is modeled on the log scale, but I find both of those really hard to think about, so we can use an identity link for both parameters like we did before with `binomial()` to think about counts and proportions instead. This makes it so the $\\phi$ parameter measures the standard deviation of the count on the count scale, so a prior like Exponential(1 / 1000) would imply that the precision (or variance-ish) of the count could vary by mostly low numbers, but maybe up to ±5000ish, which seems reasonable, especially since the Mexico part of the survey has so many respondents:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot() +\n  stat_function(fun = ~dexp(., 0.001), geom = \"area\", fill = \"#AC3414\") +\n  scale_x_continuous(labels = label_number(big.mark = \",\"), limits = c(0, 5000)) +\n  labs(x = \"Possible values for φ\", y = NULL, fill = NULL) +\n  theme_nice() +\n  theme(axis.text.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Exponential(1/1000) distribution](index_files/figure-html/plot-exponential-prior-1.png){fig-align='center' fig-alt='Exponential(1/1000) distribution' width=90%}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/q1-model-beta-binomial_b53d17482eab251344b969b2cdbf577c'}\n\n```{.r .cell-code}\noften_comics_model_beta_binomial <- brm(\n  bf(n | trials(total) ~ 0 + country),\n  data = often_comics_only,\n  family = beta_binomial(link = \"identity\", link_phi = \"identity\"),\n  prior = c(prior(beta(2, 6), class = \"b\", dpar = \"mu\", lb = 0, ub = 1),\n            prior(exponential(0.001), class = \"phi\", lb = 0)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0\n)\n## ld: warning: duplicate -rpath '/Users/andrew/.cmdstan/cmdstan-2.33.0/stan/lib/stan_math/lib/tbb' ignored\n## Start sampling\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n```\n:::\n\n\n::: {.callout-note}\n### Separate model for $\\phi$\n\nIf we wanted to be super fancy, we could define a completely separate model for the $\\phi$ part of the distribution like this, but we don't need to here:\n\n```r\noften_comics_model_beta_binomial <- brm(\n  bf(n | trials(total) ~ 0 + country,\n     phi ~ 0 + country),\n  data = often_comics_only,\n  family = beta_binomial(link = \"identity\", link_phi = \"identity\"),\n  prior = c(prior(beta(2, 6), class = \"b\", dpar = \"mu\", lb = 0, ub = 1),\n            prior(exponential(0.001), dpar = \"phi\", lb = 0)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0\n)\n```\n\n:::\n\nCheck out the results:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_comics_model_beta_binomial\n##  Family: beta_binomial \n##   Links: mu = identity; phi = identity \n## Formula: n | trials(total) ~ 0 + country \n##    Data: often_comics_only (Number of observations: 2) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## countryMexico           0.28      0.03     0.22     0.33 1.00     1786      890\n## countryUnitedStates     0.11      0.02     0.08     0.16 1.00     1626     1085\n## \n## Family Specific Parameters: \n##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## phi  1031.27   1022.22    38.29  3841.42 1.01      751      958\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nThose coefficients are the group proportions, as expected, and we have a $\\phi$ parameter representing the overall variation in counts. The proportions here are a little more uncertain than before, though, which is apparent if we plot the distributions. The distributions have a much wider range now (note that the x-axis now goes all the way up to 60%), and the densities are a lot bumpier and jankier. I don't know why though! This is weird! I'm probably doing something wrong!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noften_comics_model_beta_binomial %>% \n  epred_draws(newdata = often_comics_only) %>% \n  mutate(.epred_prop = .epred / total) %>% \n  ggplot(aes(x = .epred_prop, y = country, fill = country)) +\n  stat_halfeye() +\n  scale_x_continuous(labels = label_percent(), expand = c(0, 0.015)) +\n  scale_fill_manual(values = c(clr_usa, clr_mex)) +\n  guides(fill = \"none\") +\n  labs(x = \"Proportion of students who read comic books often\",\n       y = NULL) +\n  theme_nice()\n```\n\n::: {.cell-output-display}\n![Posterior distributions of the proportion of students who read comic books often in the United States and Mexico](index_files/figure-html/q1-plot-model-beta-binomial-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n## Final answer to the question\n\n\n\n\n\n\nPhew, that was a lot of slow pedagogical exposure. What's our <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>official estimand</span>? What's our final answer to the question \"Do respondents in Mexico read comic books more often than respondents in the United States?\"?\n\nYes. They most definitely do.\n\nIn an official sort of report or article, I'd write something like this:\n\n> Students in Mexico are far more likely to read comic books often than students in the United States. On average, 28.2% (between 27.7% and 28.6%) of PISA respondents in Mexico read comic books often, compared to 10.2% (between 9.4% and 11.1%) in the United States. There is a 95% posterior probability that the difference between these proportions is between 17.0 and 18.9 percentage points, with a median of 18.0 percentage points. This difference is substantial, and there's a 100% chance that the difference is not zero.\n\n# Question 2: Frequency of newspaper readership in the US\n\nNow that we've got the gist of proportion tests with {brms}, we'll go a lot faster for this second question. We'll forgo all frequentist stuff and the raw Stan stuff and just skip straight to the intercept-free binomial model with an identity link.\n\n## Estimand\n\nFor this question, we want to know the differences in the the proportions of American newspaper-reading frequencies, or whether the differences between (1) <span style=\"color: #E51B24\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>rarely</span> and <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>sometimes</span>, (2) <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>sometimes</span> and <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>often</span>, and (3) <span style=\"color: #E51B24\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>rarely</span> and <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>often</span> are greater than zero:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfancy_table %>% \n  tab_style(\n    style = list(\n      cell_fill(color = colorspace::lighten(\"#E51B24\", 0.8)),\n      cell_text(color = \"#E51B24\", weight = \"bold\")\n    ),\n    locations = list(\n      cells_body(columns = 3, rows = 4)\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_fill(color = colorspace::lighten(\"#FFDE00\", 0.8)),\n      cell_text(color = colorspace::darken(\"#FFDE00\", 0.1), weight = \"bold\")\n    ),\n    locations = list(\n      cells_body(columns = 4, rows = 4)\n    )\n  ) %>% \n  tab_style(\n    style = list(\n      cell_fill(color = colorspace::lighten(\"#009DDC\", 0.8)),\n      cell_text(color = \"#009DDC\", weight = \"bold\")\n    ),\n    locations = list(\n      cells_body(columns = 5, rows = 4)\n    )\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"eapktsuqxi\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#eapktsuqxi table {\n  font-family: 'Fira Sans', system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#eapktsuqxi thead, #eapktsuqxi tbody, #eapktsuqxi tfoot, #eapktsuqxi tr, #eapktsuqxi td, #eapktsuqxi th {\n  border-style: none;\n}\n\n#eapktsuqxi p {\n  margin: 0;\n  padding: 0;\n}\n\n#eapktsuqxi .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#eapktsuqxi .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#eapktsuqxi .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#eapktsuqxi .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 15px;\n  padding-right: 15px;\n  overflow-x: hidden;\n}\n\n#eapktsuqxi .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#eapktsuqxi .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#eapktsuqxi .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#eapktsuqxi .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#eapktsuqxi .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#eapktsuqxi .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#eapktsuqxi .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: bold;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#eapktsuqxi .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#eapktsuqxi .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#eapktsuqxi .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#eapktsuqxi .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#eapktsuqxi .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 15px;\n  padding-right: 15px;\n  vertical-align: top;\n}\n\n#eapktsuqxi .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#eapktsuqxi .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#eapktsuqxi .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#eapktsuqxi .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#eapktsuqxi .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#eapktsuqxi .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 15px;\n  padding-right: 15px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#eapktsuqxi .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#eapktsuqxi .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#eapktsuqxi .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 15px;\n  padding-right: 15px;\n}\n\n#eapktsuqxi .gt_left {\n  text-align: left;\n}\n\n#eapktsuqxi .gt_center {\n  text-align: center;\n}\n\n#eapktsuqxi .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#eapktsuqxi .gt_font_normal {\n  font-weight: normal;\n}\n\n#eapktsuqxi .gt_font_bold {\n  font-weight: bold;\n}\n\n#eapktsuqxi .gt_font_italic {\n  font-style: italic;\n}\n\n#eapktsuqxi .gt_super {\n  font-size: 65%;\n}\n\n#eapktsuqxi .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#eapktsuqxi .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#eapktsuqxi .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#eapktsuqxi .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#eapktsuqxi .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#eapktsuqxi .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#eapktsuqxi .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Rarely\">Rarely</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Sometimes\">Sometimes</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Often\">Often</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"Mexico\">Mexico</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.29%<br><span style='font-size:70%'>(9,897)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>45.53%<br><span style='font-size:70%'>(17,139)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>28.17%<br><span style='font-size:70%'>(10,605)</span></p>\n</div></td></tr>\n    <tr><td headers=\"Mexico  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"Mexico  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>18.02%<br><span style='font-size:70%'>(6,812)</span></p>\n</div></td>\n<td headers=\"Mexico  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>32.73%<br><span style='font-size:70%'>(12,369)</span></p>\n</div></td>\n<td headers=\"Mexico  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>49.25%<br><span style='font-size:70%'>(18,613)</span></p>\n</div></td></tr>\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"4\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"United States\">United States</th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Comic books</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>62.95%<br><span style='font-size:70%'>(3,237)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>26.86%<br><span style='font-size:70%'>(1,381)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\"><div class='gt_from_md'><p>10.19%<br><span style='font-size:70%'>(524)</span></p>\n</div></td></tr>\n    <tr><td headers=\"United States  book_type\" class=\"gt_row gt_left\"><div class='gt_from_md'><p>Newspapers</p>\n</div></td>\n<td headers=\"United States  Rarely\" class=\"gt_row gt_center\" style=\"background-color: #FFD9D9; color: #E51B24; font-weight: bold;\"><div class='gt_from_md'><p>25.27%<br><span style='font-size:70%'>(1,307)</span></p>\n</div></td>\n<td headers=\"United States  Sometimes\" class=\"gt_row gt_center\" style=\"background-color: #FFF8E4; color: #E3C508; font-weight: bold;\"><div class='gt_from_md'><p>37.22%<br><span style='font-size:70%'>(1,925)</span></p>\n</div></td>\n<td headers=\"United States  Often\" class=\"gt_row gt_center\" style=\"background-color: #D7EBFF; color: #009DDC; font-weight: bold;\"><div class='gt_from_md'><p>37.51%<br><span style='font-size:70%'>(1,940)</span></p>\n</div></td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\nWe'll again call this estimand $\\theta$, but have three different versions of it:\n\n$$\n\\begin{aligned}\n\\theta_1 &= \\pi_\\text{US, newspapers, often} - \\pi_\\text{US, newspapers, sometimes} \\\\\n\\theta_2 &= \\pi_\\text{US, newspapers, sometimes} - \\pi_\\text{US, newspapers, rarely} \\\\\n\\theta_3 &= \\pi_\\text{US, newspapers, often} - \\pi_\\text{US, newspapers, rarely}\n\\end{aligned}\n$$\nWe just spent a bunch of time talking about comic books, and now we're looking at data about newspapers and America. Who represents all three of these things simultaneously? Clark Kent / Superman, obviously, the *Daily Planet* journalist and superpowered alien dedicated to [truth, justice, and ~~the American way~~ a better tomorrow](https://variety.com/2021/film/news/superman-new-motto-dc-fandome-1235090712/). I found this palette at [Adobe Color](https://color.adobe.com/Copy%20of%20Superman-color-theme-11627723).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# US newspaper question colors\nclr_often <- \"#009DDC\"\nclr_sometimes <- \"#FFDE00\"\nclr_rarely <- \"#E51B24\"\n```\n:::\n\n\n::: {.column-margin}\n![](img/superman.jpg)\n\n[\"Superman\"](https://www.flickr.com/photos/27745117@N00/25903472957) by [Hannaford](https://www.flickr.com/photos/27745117@N00/)\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/show-superman-pal-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Bayesianly with {brms}\n\nLet's first extract the aggregated data we'll work with—newspaper frequency in the United States only:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewspapers_only <- reading_counts %>% \n  filter(book_type == \"Newspapers\", country == \"United States\")\nnewspapers_only\n## # A tibble: 3 × 6\n##   country       book_type  frequency     n total  prop\n##   <fct>         <chr>      <fct>     <int> <int> <dbl>\n## 1 United States Newspapers Rarely     1307  5172 0.253\n## 2 United States Newspapers Sometimes  1925  5172 0.372\n## 3 United States Newspapers Often      1940  5172 0.375\n```\n:::\n\n\nWe'll define this formal beta-binomial model for each of the group proportions and we'll use a Beta(2, 6) prior again (so 25% ± a bunch):\n\n$$\n\\begin{aligned}\n&\\ \\textbf{Estimands} \\\\\n\\theta_1 =&\\ \\pi_{\\text{newspapers, often}_\\text{US}} - \\pi_{\\text{newspapers, sometimes}_\\text{US}} \\\\\n\\theta_2 =&\\ \\pi_{\\text{newspapers, sometimes}_\\text{US}} - \\pi_{\\text{newspapers, rarely}_\\text{US}} \\\\\n\\theta_3 =&\\ \\pi_{\\text{newspapers, often}_\\text{US}} - \\pi_{\\text{newspapers, rarely}_\\text{US}} \\\\[10pt]\n&\\ \\textbf{Beta-binomial model} \\\\\ny_{n \\text{ newspapers, [frequency]}_\\text{US}} \\sim&\\ \\operatorname{Binomial}(n_{\\text{Total students}_\\text{US}}, \\pi_{\\text{newspapers, [frequency]}_\\text{US}}) \\\\\n\\pi_{\\text{newspapers, [frequency]}_\\text{US}} \\sim&\\ \\operatorname{Beta}(\\alpha, \\beta) \\\\[10pt]\n&\\ \\textbf{Priors} \\\\\n\\alpha =&\\ 2 \\\\\n\\beta =&\\ 6\n\\end{aligned}\n$$\n\nWe can estimate this model with {brms} using an intercept-free binomial model with an identity link:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/q2-model-identity_38d1929c3a217388626204a449d2d274'}\n\n```{.r .cell-code}\nfreq_newspapers_model <- brm(\n  bf(n | trials(total) ~ 0 + frequency),\n  data = newspapers_only,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(2, 6), class = b, lb = 0, ub = 1)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0\n)\n## ld: warning: duplicate -rpath '/Users/andrew/.cmdstan/cmdstan-2.33.0/stan/lib/stan_math/lib/tbb' ignored\n## Start sampling\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.1 seconds.\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfreq_newspapers_model\n##  Family: binomial \n##   Links: mu = identity \n## Formula: n | trials(total) ~ 0 + frequency \n##    Data: newspapers_only (Number of observations: 3) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## frequencyRarely        0.25      0.01     0.24     0.26 1.00     4536     2758\n## frequencySometimes     0.37      0.01     0.36     0.38 1.00     4084     2933\n## frequencyOften         0.37      0.01     0.36     0.39 1.00     4318     3217\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nIt works! These group proportions are the same as what we found in the contingency table:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_props_newspaper <- freq_newspapers_model %>% \n  epred_draws(newdata = newspapers_only) %>% \n  mutate(.epred_prop = .epred / total) %>% \n  ggplot(aes(x = .epred_prop, y = frequency, fill = frequency)) +\n  stat_halfeye() +\n  scale_x_continuous(labels = label_percent()) +\n  scale_fill_manual(values = c(clr_rarely, clr_sometimes, clr_often)) +\n  labs(x = \"Proportion of frequencies of newspaper reading\", y = NULL) +\n  guides(fill = \"none\") +\n  theme_nice()\nplot_props_newspaper\n```\n\n::: {.cell-output-display}\n![Posterior distributions of the proportions of the frequency of reading newspapers among American students](index_files/figure-html/q2-plot-model-identity-1.png){fig-align='center' fig-alt='Posterior distributions of the proportions of the frequency of reading newspapers among American students' width=90%}\n:::\n:::\n\n\nWe're interested in our three $\\theta$s, or the posterior differences between each of these proportions. We can again use `compare_levels()` to find these all at once. If we specify `comparison = \"pairwise\"`, {tidybayes} will calculate the differences between each pair of proportions.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfreq_newspapers_diffs <- freq_newspapers_model %>% \n  epred_draws(newdata = newspapers_only) %>% \n  mutate(.epred_prop = .epred / total) %>% \n  ungroup() %>% \n  compare_levels(.epred_prop, by = frequency) %>% \n  # Put these in the right order\n  mutate(frequency = factor(frequency, levels = c(\"Often - Sometimes\", \n                                                  \"Sometimes - Rarely\",\n                                                  \"Often - Rarely\")))\n\nfreq_newspapers_diffs %>% \n  ggplot(aes(x = .epred_prop, y = fct_rev(frequency), fill = frequency)) +\n  stat_halfeye(fill = clr_diff) +\n  geom_vline(xintercept = 0, color = \"#F012BE\") +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  guides(fill = \"none\") +\n  theme_nice()\n```\n\n::: {.cell-output-display}\n![Posterior distributions of the differences between various frequencies of reading newspapers among American students; all density plots are filled with the same color for now](index_files/figure-html/q2-plot-model-identity-diffs-1.png){fig-align='center' fig-alt='Posterior distributions of the differences between various frequencies of reading newspapers among American students; all density plots are filled with the same color for now' width=90%}\n:::\n:::\n\n\nWe can also calculate the official median differences and the probabilities that the posteriors are greater than 0:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfreq_newspapers_diffs %>% \n  summarize(median = median_qi(.epred_prop, .width = 0.95),\n            p_gt_0 = sum(.epred_prop > 0) / n()) %>% \n  unnest(median)\n## # A tibble: 3 × 8\n##   frequency                y    ymin   ymax .width .point .interval p_gt_0\n##   <fct>                <dbl>   <dbl>  <dbl>  <dbl> <chr>  <chr>      <dbl>\n## 1 Often - Sometimes  0.00268 -0.0161 0.0214   0.95 median qi         0.615\n## 2 Sometimes - Rarely 0.119    0.101  0.136    0.95 median qi         1    \n## 3 Often - Rarely     0.122    0.104  0.140    0.95 median qi         1\n```\n:::\n\n\nThere's only a 60ish% chance that the difference between <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>often</span> and <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>sometimes</span> is bigger than zero, so there's probably not an actual difference between those two categories, but there's a 100% chance that the differences between <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>sometimes</span> and <span style=\"color: #E51B24\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>rarely</span> and <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>often</span> and <span style=\"color: #E51B24\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>rarely</span> are bigger than zero.\n\n## Better fill colors\n\nBefore writing up the final official answer, we need to tweak the plot of differences. With the comic book question, we used some overly-simplified-and-wrong color theory and created a <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow</span> color for the difference (since <span style=\"color: #127088\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>blue</span> − <span style=\"color: #57643C\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>green</span> = <span style=\"color: #CD8A39\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow</span>). We could maybe do that here too, but we've actually used all primary colors in our Superman palette. I don't know what <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>blue</span> − <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow</span> or <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>yellow</span> − <span style=\"color: #E51B24\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>red</span> would be, and even if I calculated it somehow, it wouldn't be as cutely intuitive as blue minus green.\n\nSo instead, we'll do some fancy fill work with the neat [{ggpattern} package](https://coolbutuseless.github.io/package/ggpattern/), which lets us fill ggplot geoms with multiply-colored patterns. We'll fill each distribution of $\\theta$s with the combination of the two colors: we'll fill the difference between <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>often</span> and <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>sometimes</span> with stripes of those two colors, and so on.\n\nWe can't use `geom/stat_halfeye()` because {tidybayes} does fancier geom work when plotting its density slabs, but we can use `geom_density_pattern()` to create normal density plots:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfreq_newspapers_diffs %>% \n  ggplot(aes(x = .epred_prop, fill = frequency, pattern_fill = frequency)) +\n  geom_density_pattern(\n    pattern = \"stripe\",  # Stripes\n    pattern_density = 0.5,  # Take up 50% of the pattern (i.e. stripes equally sized)\n    pattern_spacing = 0.2,  # Thicker stripes\n    pattern_size = 0,  # No border on the stripes\n    trim = TRUE,  # Trim the ends of the distributions\n    linewidth = 0  # No border on the distributions\n  ) +\n  geom_vline(xintercept = 0, color = \"#F012BE\") +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  # Set colors for fills and pattern fills\n  scale_fill_manual(values = c(clr_often, clr_sometimes, clr_often)) +\n  scale_pattern_fill_manual(values = c(clr_sometimes, clr_rarely, clr_rarely)) +\n  guides(fill = \"none\", pattern_fill = \"none\") +  # Turn off legends\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  facet_wrap(vars(frequency), ncol = 1) +\n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Posterior distributions of the differences between various frequencies of reading newspapers among American students; all density plots are filled with two stripes corresponding to the difference of their two categories](index_files/figure-html/q2-diffs-plot-patterns-1.png){fig-align='center' fig-alt='Posterior distributions of the differences between various frequencies of reading newspapers among American students; all density plots are filled with two stripes corresponding to the difference of their two categories' width=90%}\n:::\n:::\n\n\nAhhh that's so cool!\n\nThe only thing that's missing is the pointrange that we get from `stat_halfeye()` that shows the median and the 50%, 80%, and 95% credible intervals. We can calculate those ourselves and add them with `geom_pointinterval()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Find medians and credible intervals\nfreq_newspapers_intervals <- freq_newspapers_diffs %>% \n  group_by(frequency) %>% \n  median_qi(.epred_prop, .width = c(0.5, 0.8, 0.95))\n\nplot_diffs_nice <- freq_newspapers_diffs %>% \n  ggplot(aes(x = .epred_prop, fill = frequency, pattern_fill = frequency)) +\n  geom_density_pattern(\n    pattern = \"stripe\",  # Stripes\n    pattern_density = 0.5,  # Take up 50% of the pattern (i.e. stripes equally sized)\n    pattern_spacing = 0.2,  # Thicker stripes\n    pattern_size = 0,  # No border on the stripes\n    trim = TRUE,  # Trim the ends of the distributions\n    linewidth = 0  # No border on the distributions\n  ) +\n  # Add 50%, 80%, and 95% intervals + median\n  geom_pointinterval(data = freq_newspapers_intervals, \n                     aes(x = .epred_prop, xmin = .lower, xmax = .upper)) +\n  geom_vline(xintercept = 0, color = \"#F012BE\") +\n  # Multiply axis limits by 0.5% so that the right \"pp.\" isn't cut off\n  scale_x_continuous(labels = label_pp, expand = c(0, 0.005)) +\n  # Set colors for fills and pattern fills\n  scale_fill_manual(values = c(clr_often, clr_sometimes, clr_often)) +\n  scale_pattern_fill_manual(values = c(clr_sometimes, clr_rarely, clr_rarely)) +\n  guides(fill = \"none\", pattern_fill = \"none\") +  # Turn off legends\n  labs(x = \"Percentage point difference in proportions\",\n       y = NULL) +\n  facet_wrap(vars(frequency), ncol = 1) +\n  # Make it so the pointrange doesn't get cropped\n  coord_cartesian(clip = \"off\") + \n  theme_nice() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank())\nplot_diffs_nice\n```\n\n::: {.cell-output-display}\n![Posterior distributions of the differences between various frequencies of reading newspapers among American students; density plots are filled with stripes and a pointrange shows the median and 50%, 80%, and 95% credible intervals](index_files/figure-html/q2-diffs-plot-patterns-pointrange-1.png){fig-align='center' fig-alt='Posterior distributions of the differences between various frequencies of reading newspapers among American students; density plots are filled with stripes and a pointrange shows the median and 50%, 80%, and 95% credible intervals' width=90%}\n:::\n:::\n\n\nPerfect!\n\n\n## Final answer to the question\n\n\n\n\n\nSo, given these results, what's the answer to the question \"Do students in the United States vary in their frequency of reading newspapers?\"? What are our three $\\theta$s? The frequencies vary, but only between <span style=\"color: #E51B24\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>rarely</span> and the other two categories. There's no difference between <span style=\"color: #FFDE00\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>sometimes</span> and <span style=\"color: #009DDC\"><i class=\"magic-block\" aria-hidden=\"true\">■</i>often</span>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(\n  (plot_props_newspaper + labs(x = \"Proportions\") + \n     facet_wrap(vars(\"Response proportions\"))) | \n    plot_spacer() |\n    (plot_diffs_nice + labs(x = \"Percentage point differences\"))\n) +\n  plot_layout(widths = c(0.475, 0.05, 0.475))\n```\n\n::: {.cell-output-display}\n![Posterior distribution of the proportions and difference in proportions of the frequency of reading newspapers among American students](index_files/figure-html/q2-plot-final-1.png){fig-align='center' fig-alt='Posterior distribution of the proportions and difference in proportions of the frequency of reading newspapers among American students' width=100%}\n:::\n:::\n\n\nHere's how I'd write about the results:\n\n> Students in the United States tend to read the newspaper at least sometimes, and are least likely to read it rarely. On average, 25.3% of American PISA respondents report reading the newspaper rarely (with a 95% credible interval of between 24.1% and 26.5%), compared to 37.2% reading sometimes (35.9%–38.5%) and 37.5% reading sometimes (36.2%–38.8%). \n> \n> There is no substantial difference in proportions between those reporting reading newspapers often and sometimes. The posterior median difference is between −1.6 and 2.1 percentage points, with a median of 0.3 percentage points, and there's only a 61.5% probability that this difference is greater than 0, which implies that the two categories are indistinguishable from each other. \n> \n> There *is* a clear substantial difference between the proportion reading newspapers rarely and the other two responses, though. The posterior median difference between sometimes and rarely is between 10.1 and 13.6 percentage points (median = 11.9), while the difference between often and rarely is between 10.4 and 14.0 percentage points (median = 12.2). The probability that each of these differences is greater than 0 is 100%.\n\n---\n\nEt voila! Principled, easily interpretable, non-golem-based tests of differences in proportions using Bayesian statistics!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
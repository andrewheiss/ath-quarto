---
title: "Manually generate predicted values for logistic regression with matrix multiplication in R"
date: 2023-08-15
description: "This is like basic stats stuff, but I can never remember how to do it—here's how to use matrix multiplication to replicate the results of `predict()`"
image: social-image.png
twitter-card:
  image: "social-image.png"
open-graph:
  image: "social-image.png"
categories:
  - r
  - statistics
  - regression
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE
)

options(
  digits = 4,
  width = 300,
  dplyr.summarise.inform = FALSE
)

set.seed(1234)
```

In a project I'm working on, I need to generate predictions from a logistic regression model. That's typically a really straightforward task—we can just use `predict()` to plug a dataset of values into a model, which will spit out predictions either on the (gross, uninterpretable) log odds scale or on the (nice, interpretable) percentage-point scale.^[And for pro-level predictions, use `predictions()` from [{marginaleffects}](https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html).]

However, in this project I cannot use `predict()`—I'm working with a big matrix of posterior coefficient draws from a Bayesian model fit with raw Stan code, so there's no special `predict()` function that will work. Instead, I need to use matrix multiplication and manually multiply a matrix of new data with a vector of slopes from the model. 

I haven't had to matrix multiply coefficients with data since my first PhD stats class back in 2012 and I've completely forgotten how. 

I created this little guide as a reference for myself, and I figured it'd probably be useful for others, so up on the blog it goes ([see the introduction to this post for more about my philosophy of public work](https://www.andrewheiss.com/blog/2022/05/20/marginalia/index.html)).

![Image generated with Bing Image Creator with the prompt "regression matrix multiplication in a sketchy style"](social-image.png)

## Example 1: Logistic regression model with an intercept and slopes

Here's a basic regression model where we predict if a penguin is a Gentoo based on its bill length and body mass. 

```{r load-data-make-model1}
library(palmerpenguins)

penguins <- penguins |> 
  tidyr::drop_na(sex) |> 
  dplyr::mutate(is_gentoo = species == "Gentoo")

model <- glm(
  is_gentoo ~ bill_length_mm + body_mass_g,
  data = penguins,
  family = binomial(link = "logit")
)
```

We can generate predicted values across different three different values of bill length: 40 mm, 44 mm, and 48 mm, holding body mass constant at the average (`r round(mean(penguins$body_mass_g), 0)` g):

```{r make-data-grid}
data_to_plug_in <- expand.grid(
  bill_length_mm = c(40, 44, 48),
  body_mass_g = mean(penguins$body_mass_g)
)
data_to_plug_in
```

We can feed this little dataset into the model using `predict()`, which can generate predictions as log odds (`type = "link"`) or probabilities (`type = "response"`):

```{r predict-model1-auto}
predict(model, newdata = data_to_plug_in, type = "link")
predict(model, newdata = data_to_plug_in, type = "response")
```

Yay, nice and easy.

Here's how to do the same thing with manual matrix multiplication:

```{r predict-model1-manual}
# Get all the coefficients
(coefs <- coef(model))

# Split intercept and slope coefficients into separate objects
(intercept <- coefs[1])
(slopes <- coefs[-1])

# Convert the data frame of new data into a matrix
(data_to_plug_in_mat <- as.matrix(data_to_plug_in))

# Matrix multiply the new data with the slope coefficients, then add the intercept
(log_odds <- as.numeric((data_to_plug_in_mat %*% slopes) + intercept))

# Convert to probability scale
plogis(log_odds)
```

The results are the same as `predict()`:

```{r compare-model1-preds}
predict(model, newdata = data_to_plug_in, type = "link")
log_odds

predict(model, newdata = data_to_plug_in, type = "response")
plogis(log_odds)
```


## Example 2: Logistic regression model with a categorical predictor and no intercept

This gets a little more complex when working with categorical predictors, especially if you've omitted the intercept term. For instance, in the data I'm working with, we have a model that looks something like this, with `0` added as a term to suppress the intercept and give separate coefficients for each of the levels of `sex`:

```{r make-model2}
model_categorical <- glm(
  is_gentoo ~ 0 + sex + bill_length_mm + body_mass_g,
  data = penguins,
  family = binomial(link = "logit")
)
coef(model_categorical)
```

When using `predict()`, we don't have to do anything special with this intercept-free model. We can plug in a dataset with different variations of predictors:

```{r predict-model2-auto}
data_to_plug_in_cat <- expand.grid(
  sex = c("female", "male"),
  bill_length_mm = c(40, 44, 48),
  body_mass_g = mean(penguins$body_mass_g)
)
data_to_plug_in_cat

predict(model_categorical, newdata = data_to_plug_in_cat, type = "link")
predict(model_categorical, newdata = data_to_plug_in_cat, type = "response")
```

If we want to do this manually, we have to create a matrix version of `data_to_plug_in_cat` that has separate columns for `sexfemale` and `sexmale`. We can't just use `as.matrix(data_to_plug_in_cat)`, since that only has a single column for `sex` (and because that column contains text, it forces the rest of the matrix to be text, which makes it so we can't do math with it anymore):

```{r model2-data-wrong}
as.matrix(data_to_plug_in_cat)
```

Instead, we can use `model.matrix()` to create a design matrix—also called a dummy-encoded matrix^[Though we should probably quit using the word "dummy" because of its ableist connotations—see [Google's developer documentation style guide for alternatives](https://developers.google.com/style/word-list#dummy-variable).] or a one-hot encoded matrix—which makes columns of 0s and 1s for each of the levels of `sex`

```{r make-datagrid-model2-design}
data_to_plug_in_cat_mat <- model.matrix(
  ~ 0 + ., data = data_to_plug_in_cat
)
data_to_plug_in_cat_mat
```

We can now do math with this matrix. Since we don't have an intercept term, we don't need to create separate objects for the slopes and intercepts and can matrix multiply the new data matrix with the model coefficients:

```{r predict-model2-manual}
# Get all the coefficients
(coefs_cat <- coef(model_categorical))

# Matrix multiply the newdata with the slope coefficients
(log_odds_cat <- as.numeric(data_to_plug_in_cat_mat %*% coefs_cat))

# Convert to probability scale
plogis(log_odds_cat)
```

The results are the same!

```{r compare-model2-preds}
predict(model_categorical, newdata = data_to_plug_in_cat, type = "link")
log_odds_cat

predict(model_categorical, newdata = data_to_plug_in_cat, type = "response")
plogis(log_odds_cat)
```
